{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SPADE Experiment Example\n",
        "\n",
        "This notebook loads one of the LangChain pipelines, annotated examples, and displays the SPADE-generated assertions. You must specify the pipeline name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace this with one of the 9 pipelines in the paper\n",
        "\n",
        "PIPELINE_NAME = \"codereviews\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print the last prompt template, an example, and a sample of 5 candidate assertions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Last prompt template:\n",
              "You are an AI Assistant that’s an expert at reviewing pull requests. Review the below pull request that you \n",
              "receive. \n",
              "\n",
              "Input format\n",
              "- The input format follows Github diff format with addition and subtraction of code.\n",
              "- The + sign means that code has been added.\n",
              "- The - sign means that code has been removed.\n",
              "\n",
              "Instructions\n",
              "- Take into account that you don’t have access to the full code but only the code diff.\n",
              "- Only answer on what can be improved and provide the improvement in code. \n",
              "- Answer in short form. \n",
              "- Include code snippets if necessary.\n",
              "- Adhere to the languages code conventions.\n",
              "- Make it personal and always show gratitude to the author using <span style=\"color: #008000; text-decoration-color: #008000\">\"@\"</span> when tagging.\n",
              "\n",
              "\n",
              "\n",
              "<span style=\"font-weight: bold\">{</span>pr_webhook_payload<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Last prompt template:\n",
              "You are an AI Assistant that’s an expert at reviewing pull requests. Review the below pull request that you \n",
              "receive. \n",
              "\n",
              "Input format\n",
              "- The input format follows Github diff format with addition and subtraction of code.\n",
              "- The + sign means that code has been added.\n",
              "- The - sign means that code has been removed.\n",
              "\n",
              "Instructions\n",
              "- Take into account that you don’t have access to the full code but only the code diff.\n",
              "- Only answer on what can be improved and provide the improvement in code. \n",
              "- Answer in short form. \n",
              "- Include code snippets if necessary.\n",
              "- Adhere to the languages code conventions.\n",
              "- Make it personal and always show gratitude to the author using \u001b[32m\"@\"\u001b[0m when tagging.\n",
              "\n",
              "\n",
              "\n",
              "\u001b[1m{\u001b[0mpr_webhook_payload\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Last example:\n",
              "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'pr_webhook_payload'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"title\": \"Integrate Core Data for Local Persistence\", \"description\": \"Implementing Core </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Data to manage local data persistence in the app.\", \"author\": \"@coreDataPro\", \"diff\": [{\"file\": </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"DataController.swift\", \"additions\": \"\\\\n+ import CoreData\\\\n+\\\\n+ class DataController {\\\\n+     static let shared</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">= DataController()\\\\n+\\\\n+     let persistentContainer: NSPersistentContainer\\\\n+\\\\n+     private init() {\\\\n+     </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">persistentContainer = NSPersistentContainer(name: \\\\\"MyAppModel\\\\\")\\\\n+         </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">persistentContainer.loadPersistentStores { (storeDescription, error) in\\\\n+             if let error = error as </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">NSError? {\\\\n+                 fatalError(\\\\\"Unresolved error \\\\\\\\(error), \\\\\\\\(error.userInfo)\\\\\")\\\\n+            </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">}\\\\n+         }\\\\n+     }\\\\n+\\\\n+     // Core Data saving support\\\\n+     func saveContext () {\\\\n+         let </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">context = persistentContainer.viewContext\\\\n+         if context.hasChanges {\\\\n+             do {\\\\n+             </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">try context.save()\\\\n+             } catch {\\\\n+                 let nserror = error as NSError\\\\n+                </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">fatalError(\\\\\"Unresolved error \\\\\\\\(nserror), \\\\\\\\(nserror.userInfo)\\\\\")\\\\n+             }\\\\n+         }\\\\n+     </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">}\\\\n+ }\\\\n      \", \"deletions\": \"\"}]}'</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Last example:\n",
              "\u001b[1m{\u001b[0m\u001b[32m'pr_webhook_payload'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"title\": \"Integrate Core Data for Local Persistence\", \"description\": \"Implementing Core \u001b[0m\n",
              "\u001b[32mData to manage local data persistence in the app.\", \"author\": \"@coreDataPro\", \"diff\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"file\": \u001b[0m\n",
              "\u001b[32m\"DataController.swift\", \"additions\": \"\\\\n+ import CoreData\\\\n+\\\\n+ class DataController \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\n+     static let shared\u001b[0m\n",
              "\u001b[32m= DataController\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n+\\\\n+     let persistentContainer: NSPersistentContainer\\\\n+\\\\n+     private init\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\n+     \u001b[0m\n",
              "\u001b[32mpersistentContainer = NSPersistentContainer\u001b[0m\u001b[32m(\u001b[0m\u001b[32mname: \\\\\"MyAppModel\\\\\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n+         \u001b[0m\n",
              "\u001b[32mpersistentContainer.loadPersistentStores \u001b[0m\u001b[32m{\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mstoreDescription, error\u001b[0m\u001b[32m)\u001b[0m\u001b[32m in\\\\n+             if let error = error as \u001b[0m\n",
              "\u001b[32mNSError? \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\n+                 fatalError\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\\"Unresolved error \\\\\\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32merror\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \\\\\\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32merror.userInfo\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n+            \u001b[0m\n",
              "\u001b[32m}\u001b[0m\u001b[32m\\\\n+         \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n+     \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n+\\\\n+     // Core Data saving support\\\\n+     func saveContext \u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\n+         let \u001b[0m\n",
              "\u001b[32mcontext = persistentContainer.viewContext\\\\n+         if context.hasChanges \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\n+             do \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\n+             \u001b[0m\n",
              "\u001b[32mtry context.save\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n+             \u001b[0m\u001b[32m}\u001b[0m\u001b[32m catch \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\n+                 let nserror = error as NSError\\\\n+                \u001b[0m\n",
              "\u001b[32mfatalError\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\\"Unresolved error \\\\\\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mnserror\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \\\\\\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mnserror.userInfo\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n+             \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n+         \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n+     \u001b[0m\n",
              "\u001b[32m}\u001b[0m\u001b[32m\\\\n+ \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n      \", \"deletions\": \"\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sample of candidate assertions:\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Sample of candidate assertions:\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">async def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">assert_includes_code_improvements_v1</span><span style=\"font-weight: bold\">(</span>\n",
              "    example: dict, prompt: str, response: str\n",
              "<span style=\"font-weight: bold\">)</span> -&gt; bool:\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    Check if the response includes code improvement suggestions.\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    # It's expected that the response must contain the word <span style=\"color: #008000; text-decoration-color: #008000\">\"improvement\"</span> or modifications in the code snippet\n",
              "    improvements_keywords = <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"improvement\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"improve\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"refactor\"</span><span style=\"font-weight: bold\">]</span>\n",
              "    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">any</span><span style=\"font-weight: bold\">(</span>keyword in response for keyword in improvements_keywords<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "async def \u001b[1;35massert_includes_code_improvements_v1\u001b[0m\u001b[1m(\u001b[0m\n",
              "    example: dict, prompt: str, response: str\n",
              "\u001b[1m)\u001b[0m -> bool:\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    Check if the response includes code improvement suggestions.\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    # It's expected that the response must contain the word \u001b[32m\"improvement\"\u001b[0m or modifications in the code snippet\n",
              "    improvements_keywords = \u001b[1m[\u001b[0m\u001b[32m\"improvement\"\u001b[0m, \u001b[32m\"improve\"\u001b[0m, \u001b[32m\"refactor\"\u001b[0m\u001b[1m]\u001b[0m\n",
              "    return \u001b[1;35many\u001b[0m\u001b[1m(\u001b[0mkeyword in response for keyword in improvements_keywords\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">async def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">assert_response_follows_review_format_v1</span><span style=\"font-weight: bold\">(</span>\n",
              "    example: dict, prompt: str, response: str\n",
              "<span style=\"font-weight: bold\">)</span> -&gt; bool:\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    Check if the response follows a specific format resembling a code review,\n",
              "    which includes a title, author mention, gratitude, and listed improvements.\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    response_lines = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">response.split</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"\\n\"</span><span style=\"font-weight: bold\">)</span>\n",
              "    has_title = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">any</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Title:\"</span> in line for line in response_lines<span style=\"font-weight: bold\">)</span>\n",
              "    has_author = example<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"author\"</span><span style=\"font-weight: bold\">]</span> in response\n",
              "    has_gratitude = <span style=\"color: #008000; text-decoration-color: #008000\">\"thank you\"</span> in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">response.lower</span><span style=\"font-weight: bold\">()</span> or <span style=\"color: #008000; text-decoration-color: #008000\">\"thanks\"</span> in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">response.lower</span><span style=\"font-weight: bold\">()</span>\n",
              "    has_improvements = <span style=\"color: #008000; text-decoration-color: #008000\">\"Improvements:\"</span> in response or <span style=\"color: #008000; text-decoration-color: #008000\">\"improvement:\"</span> in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">response.lower</span><span style=\"font-weight: bold\">()</span>\n",
              "\n",
              "    return has_title and has_author and has_gratitude and has_improvements\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "async def \u001b[1;35massert_response_follows_review_format_v1\u001b[0m\u001b[1m(\u001b[0m\n",
              "    example: dict, prompt: str, response: str\n",
              "\u001b[1m)\u001b[0m -> bool:\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    Check if the response follows a specific format resembling a code review,\n",
              "    which includes a title, author mention, gratitude, and listed improvements.\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    response_lines = \u001b[1;35mresponse.split\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"\\n\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "    has_title = \u001b[1;35many\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"Title:\"\u001b[0m in line for line in response_lines\u001b[1m)\u001b[0m\n",
              "    has_author = example\u001b[1m[\u001b[0m\u001b[32m\"author\"\u001b[0m\u001b[1m]\u001b[0m in response\n",
              "    has_gratitude = \u001b[32m\"thank you\"\u001b[0m in \u001b[1;35mresponse.lower\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m or \u001b[32m\"thanks\"\u001b[0m in \u001b[1;35mresponse.lower\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "    has_improvements = \u001b[32m\"Improvements:\"\u001b[0m in response or \u001b[32m\"improvement:\"\u001b[0m in \u001b[1;35mresponse.lower\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "    return has_title and has_author and has_gratitude and has_improvements\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">async def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">assert_examples_of_improvement_follow_code_conventions_v1</span><span style=\"font-weight: bold\">(</span>\n",
              "    example: dict, prompt: str, response: str\n",
              "<span style=\"font-weight: bold\">)</span> -&gt; bool:\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    Check if the examples of improvements in the response follow the code conventions\n",
              "    of the language <span style=\"font-weight: bold\">(</span>Python in this case<span style=\"font-weight: bold\">)</span>, checking for syntax correctness.\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    # Example Python code to check for syntax errors in response\n",
              "    try:\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">exec</span><span style=\"font-weight: bold\">(</span>response<span style=\"font-weight: bold\">)</span>\n",
              "    except SyntaxError:\n",
              "        return <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "    return <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "async def \u001b[1;35massert_examples_of_improvement_follow_code_conventions_v1\u001b[0m\u001b[1m(\u001b[0m\n",
              "    example: dict, prompt: str, response: str\n",
              "\u001b[1m)\u001b[0m -> bool:\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    Check if the examples of improvements in the response follow the code conventions\n",
              "    of the language \u001b[1m(\u001b[0mPython in this case\u001b[1m)\u001b[0m, checking for syntax correctness.\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    # Example Python code to check for syntax errors in response\n",
              "    try:\n",
              "        \u001b[1;35mexec\u001b[0m\u001b[1m(\u001b[0mresponse\u001b[1m)\u001b[0m\n",
              "    except SyntaxError:\n",
              "        return \u001b[3;91mFalse\u001b[0m\n",
              "    return \u001b[3;92mTrue\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">async def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">assert_response_adheres_to_workflow_v1</span><span style=\"font-weight: bold\">(</span>\n",
              "    example: dict, prompt: str, response: str\n",
              "<span style=\"font-weight: bold\">)</span> -&gt; bool:\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    Check that the response adheres to the workflow of discussing only the code in the diff,\n",
              "    with no assumptions or extrapolations outside of the provided code segment.\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    question = <span style=\"color: #008000; text-decoration-color: #008000\">\"Does the response adhere to the workflow by discussing the code diff without making assumptions </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">about the unseen code?\"</span>\n",
              "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ask_llm</span><span style=\"font-weight: bold\">(</span>prompt, response, question<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "async def \u001b[1;35massert_response_adheres_to_workflow_v1\u001b[0m\u001b[1m(\u001b[0m\n",
              "    example: dict, prompt: str, response: str\n",
              "\u001b[1m)\u001b[0m -> bool:\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    Check that the response adheres to the workflow of discussing only the code in the diff,\n",
              "    with no assumptions or extrapolations outside of the provided code segment.\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    question = \u001b[32m\"Does the response adhere to the workflow by discussing the code diff without making assumptions \u001b[0m\n",
              "\u001b[32mabout the unseen code?\"\u001b[0m\n",
              "    return await \u001b[1;35mask_llm\u001b[0m\u001b[1m(\u001b[0mprompt, response, question\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">async def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">assert_recognition_of_code_conventions_v1</span><span style=\"font-weight: bold\">(</span>\n",
              "    example: dict, prompt: str, response: str\n",
              "<span style=\"font-weight: bold\">)</span> -&gt; bool:\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    Check that the response includes recognition of the coding conventions, such as the use of snake_case for \n",
              "function names in Python.\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    question = <span style=\"color: #008000; text-decoration-color: #008000\">\"Does the response recognize and adhere to the code conventions of Python, including proper naming </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">and style?\"</span>\n",
              "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ask_llm</span><span style=\"font-weight: bold\">(</span>prompt, response, question<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "async def \u001b[1;35massert_recognition_of_code_conventions_v1\u001b[0m\u001b[1m(\u001b[0m\n",
              "    example: dict, prompt: str, response: str\n",
              "\u001b[1m)\u001b[0m -> bool:\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    Check that the response includes recognition of the coding conventions, such as the use of snake_case for \n",
              "function names in Python.\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    question = \u001b[32m\"Does the response recognize and adhere to the code conventions of Python, including proper naming \u001b[0m\n",
              "\u001b[32mand style?\"\u001b[0m\n",
              "    return await \u001b[1;35mask_llm\u001b[0m\u001b[1m(\u001b[0mprompt, response, question\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import_str = f\"from paper_experiments.{PIPELINE_NAME}.prompt_templates import TEMPLATES; from paper_experiments.{PIPELINE_NAME}.examples import EXAMPLES; from paper_experiments.{PIPELINE_NAME}.candidate_assertions import ALL_FUNCTIONS\"\n",
        "exec(import_str)\n",
        "from rich import print as rprint\n",
        "import inspect\n",
        "\n",
        "# Print the last prompt template and example\n",
        "rprint(f\"Last prompt template:\\n{TEMPLATES[-1]}\")\n",
        "rprint(f\"Last example:\\n{EXAMPLES[-1]}\")\n",
        "rprint(f\"Sample of candidate assertions:\")\n",
        "\n",
        "for f in ALL_FUNCTIONS[:5]:\n",
        "    rprint(inspect.getsource(f))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the cached pipeline results for the examples and join with the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c26484e8b8cb09a62f72d2fa70de3ef466a5a4381bdabe91d0805ceb3eb2929f\n",
            "Found cached results\n",
            "There are 3344 results (approx num assertions * num examples b/c there are some errors).\n"
          ]
        }
      ],
      "source": [
        "# Load cached responses\n",
        "\n",
        "from spade.execute_assertions import execute_candidate_assertions\n",
        "\n",
        "pipeline_results = await execute_candidate_assertions(PIPELINE_NAME, TEMPLATES[-1], EXAMPLES, ALL_FUNCTIONS)\n",
        "rprint(f\"There are {len(pipeline_results)} results (approx num assertions * num examples b/c there are some errors).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">There are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span> labeled responses. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> are successful <span style=\"font-weight: bold\">(</span>i.e., good<span style=\"font-weight: bold\">)</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> are failures <span style=\"font-weight: bold\">(</span>i.e., bad<span style=\"font-weight: bold\">)</span>.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "There are \u001b[1;36m76\u001b[0m labeled responses. \u001b[1;36m60\u001b[0m are successful \u001b[1m(\u001b[0mi.e., good\u001b[1m)\u001b[0m, \u001b[1;36m16\u001b[0m are failures \u001b[1m(\u001b[0mi.e., bad\u001b[1m)\u001b[0m.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the optimizer input, labeled responses, and subsumption results\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "labeled_responses = pd.read_csv(f\"paper_experiments/{PIPELINE_NAME}/labeled_responses.csv\")\n",
        "rprint(f\"There are {len(labeled_responses)} labeled responses. {len(labeled_responses[labeled_responses['label'] == True])} are successful (i.e., good), {len(labeled_responses[labeled_responses['label'] == False])} are failures (i.e., bad).\")\n",
        "\n",
        "# Join the labeled responses with the pipeline results\n",
        "results_and_labels = pipeline_results.merge(labeled_responses, on=[\"response\"])\n",
        "\n",
        "# Load subsumption results\n",
        "subsumption_results = pd.read_csv(f\"paper_experiments/{PIPELINE_NAME}/subsumption_results.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline responses for some examples and their labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>example</th>\n",
              "      <th>response</th>\n",
              "      <th>model</th>\n",
              "      <th>function_name</th>\n",
              "      <th>result</th>\n",
              "      <th>prompt_tokens</th>\n",
              "      <th>completion_tokens</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1264</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Integrate S...</td>\n",
              "      <td>Hello @secureRust,\\n\\nThank you for your contr...</td>\n",
              "      <td>gpt-4</td>\n",
              "      <td>assert_completeness_in_reviewing_code_diff</td>\n",
              "      <td>False</td>\n",
              "      <td>669.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Add TCP con...</td>\n",
              "      <td>Thank you for the PR @rustNetDev! Your effort ...</td>\n",
              "      <td>gpt-4</td>\n",
              "      <td>assert_response_is_personal_and_grateful_v2</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Implement b...</td>\n",
              "      <td>Thank you @rustNetworkDev for the contribution...</td>\n",
              "      <td>gpt-4</td>\n",
              "      <td>assert_proper_acknowledgement_v1</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1810</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Function to...</td>\n",
              "      <td>@goDeveloper, thank you for the pull request. ...</td>\n",
              "      <td>gpt-3</td>\n",
              "      <td>assert_response_is_personal_and_grateful_v1</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2145</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Use Go chan...</td>\n",
              "      <td>Hey @goChannelExpert, thanks for the contribut...</td>\n",
              "      <td>gpt-4</td>\n",
              "      <td>assert_consistency_with_tasks_and_instructions</td>\n",
              "      <td>True</td>\n",
              "      <td>645.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1612</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Function to...</td>\n",
              "      <td>Thank you for the PR, @secretManager! I notice...</td>\n",
              "      <td>gpt-4</td>\n",
              "      <td>assert_response_is_concise_and_clear</td>\n",
              "      <td>True</td>\n",
              "      <td>840.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Enhance PyT...</td>\n",
              "      <td>Thank you for your pull request, @pytorchEnhan...</td>\n",
              "      <td>gpt-4</td>\n",
              "      <td>assert_respects_information_limitation_v1</td>\n",
              "      <td>True</td>\n",
              "      <td>578.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1507</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Setup Kuber...</td>\n",
              "      <td>Thank you @kubeDev for the pull request to ini...</td>\n",
              "      <td>gpt-4</td>\n",
              "      <td>assert_follows_code_conventions_v1</td>\n",
              "      <td>False</td>\n",
              "      <td>721.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Fix race co...</td>\n",
              "      <td>@nodeAsyncFix, thank you for the pull request!...</td>\n",
              "      <td>gpt-3</td>\n",
              "      <td>assert_response_follows_review_format_v1</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>user:\\nYou are an AI Assistant that’s an exper...</td>\n",
              "      <td>{'pr_webhook_payload': '{\"title\": \"Function to...</td>\n",
              "      <td>Thank you for the PR, @secretManager! I notice...</td>\n",
              "      <td>gpt-4</td>\n",
              "      <td>assert_response_is_brief_v1</td>\n",
              "      <td>True</td>\n",
              "      <td>845.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 prompt  \\\n",
              "1264  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "1068  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "1345  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "1810  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "2145  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "1612  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "2499  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "1507  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "2245  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "1594  user:\\nYou are an AI Assistant that’s an exper...   \n",
              "\n",
              "                                                example  \\\n",
              "1264  {'pr_webhook_payload': '{\"title\": \"Integrate S...   \n",
              "1068  {'pr_webhook_payload': '{\"title\": \"Add TCP con...   \n",
              "1345  {'pr_webhook_payload': '{\"title\": \"Implement b...   \n",
              "1810  {'pr_webhook_payload': '{\"title\": \"Function to...   \n",
              "2145  {'pr_webhook_payload': '{\"title\": \"Use Go chan...   \n",
              "1612  {'pr_webhook_payload': '{\"title\": \"Function to...   \n",
              "2499  {'pr_webhook_payload': '{\"title\": \"Enhance PyT...   \n",
              "1507  {'pr_webhook_payload': '{\"title\": \"Setup Kuber...   \n",
              "2245  {'pr_webhook_payload': '{\"title\": \"Fix race co...   \n",
              "1594  {'pr_webhook_payload': '{\"title\": \"Function to...   \n",
              "\n",
              "                                               response  model  \\\n",
              "1264  Hello @secureRust,\\n\\nThank you for your contr...  gpt-4   \n",
              "1068  Thank you for the PR @rustNetDev! Your effort ...  gpt-4   \n",
              "1345  Thank you @rustNetworkDev for the contribution...  gpt-4   \n",
              "1810  @goDeveloper, thank you for the pull request. ...  gpt-3   \n",
              "2145  Hey @goChannelExpert, thanks for the contribut...  gpt-4   \n",
              "1612  Thank you for the PR, @secretManager! I notice...  gpt-4   \n",
              "2499  Thank you for your pull request, @pytorchEnhan...  gpt-4   \n",
              "1507  Thank you @kubeDev for the pull request to ini...  gpt-4   \n",
              "2245  @nodeAsyncFix, thank you for the pull request!...  gpt-3   \n",
              "1594  Thank you for the PR, @secretManager! I notice...  gpt-4   \n",
              "\n",
              "                                       function_name  result  prompt_tokens  \\\n",
              "1264      assert_completeness_in_reviewing_code_diff   False          669.0   \n",
              "1068     assert_response_is_personal_and_grateful_v2   False            NaN   \n",
              "1345                assert_proper_acknowledgement_v1   False            NaN   \n",
              "1810     assert_response_is_personal_and_grateful_v1    True            NaN   \n",
              "2145  assert_consistency_with_tasks_and_instructions    True          645.0   \n",
              "1612            assert_response_is_concise_and_clear    True          840.0   \n",
              "2499       assert_respects_information_limitation_v1    True          578.0   \n",
              "1507              assert_follows_code_conventions_v1   False          721.0   \n",
              "2245        assert_response_follows_review_format_v1   False            NaN   \n",
              "1594                     assert_response_is_brief_v1    True          845.0   \n",
              "\n",
              "      completion_tokens  label  \n",
              "1264                1.0      1  \n",
              "1068                NaN      1  \n",
              "1345                NaN      1  \n",
              "1810                NaN      1  \n",
              "2145                1.0      1  \n",
              "1612                1.0      1  \n",
              "2499                1.0      0  \n",
              "1507                1.0      0  \n",
              "2245                NaN      1  \n",
              "1594                1.0      1  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Randomly sample 10 results and their labels\n",
        "\n",
        "results_and_labels.sample(frac=1).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List all subsumption pairs identified by the LLM\n",
        "\n",
        "A -> B means that A subsumes B. Note that some subsumption pairs are not explicitly identified by the LLM (i.e., asked_LLM = False, but we construct this edge via transitivity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>func A</th>\n",
              "      <th>func B</th>\n",
              "      <th>A -&gt; B</th>\n",
              "      <th>asked_LLM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>async def assert_response_is_personal_and_grat...</td>\n",
              "      <td>async def assert_proper_acknowledgement_v1(exa...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>async def assert_response_is_personal_and_grat...</td>\n",
              "      <td>async def assert_gratitude_personal_touch(exam...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>async def assert_response_follows_review_forma...</td>\n",
              "      <td>async def assert_response_is_personal_and_grat...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>async def assert_response_is_brief_v1(example:...</td>\n",
              "      <td>async def assert_response_is_concise_v1(\\n    ...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>async def assert_contains_brief_answers_v1(exa...</td>\n",
              "      <td>async def assert_response_is_brief_v1(example:...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>async def assert_response_is_concise_and_clear...</td>\n",
              "      <td>async def assert_response_is_concise_v1(\\n    ...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>async def assert_response_is_concise_and_clear...</td>\n",
              "      <td>async def assert_clear_professional_language_v...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>async def assert_excludes_irrelevant_content_v...</td>\n",
              "      <td>async def assert_excludes_unrelated_topics_or_...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>async def assert_response_does_not_require_ful...</td>\n",
              "      <td>async def assert_excludes_full_codebase_review...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>async def assert_excludes_full_codebase_review...</td>\n",
              "      <td>async def assert_response_does_not_require_ful...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>async def assert_response_follows_review_forma...</td>\n",
              "      <td>async def assert_proper_acknowledgement_v1(exa...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>async def assert_response_follows_review_forma...</td>\n",
              "      <td>async def assert_gratitude_personal_touch(exam...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>async def assert_contains_brief_answers_v1(exa...</td>\n",
              "      <td>async def assert_response_is_concise_v1(\\n    ...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                func A  \\\n",
              "0    async def assert_response_is_personal_and_grat...   \n",
              "1    async def assert_response_is_personal_and_grat...   \n",
              "2    async def assert_response_follows_review_forma...   \n",
              "3    async def assert_response_is_brief_v1(example:...   \n",
              "4    async def assert_contains_brief_answers_v1(exa...   \n",
              "5    async def assert_response_is_concise_and_clear...   \n",
              "6    async def assert_response_is_concise_and_clear...   \n",
              "7    async def assert_excludes_irrelevant_content_v...   \n",
              "8    async def assert_response_does_not_require_ful...   \n",
              "9    async def assert_excludes_full_codebase_review...   \n",
              "42   async def assert_response_follows_review_forma...   \n",
              "43   async def assert_response_follows_review_forma...   \n",
              "858  async def assert_contains_brief_answers_v1(exa...   \n",
              "\n",
              "                                                func B  A -> B  asked_LLM  \n",
              "0    async def assert_proper_acknowledgement_v1(exa...    True       True  \n",
              "1    async def assert_gratitude_personal_touch(exam...    True       True  \n",
              "2    async def assert_response_is_personal_and_grat...    True       True  \n",
              "3    async def assert_response_is_concise_v1(\\n    ...    True       True  \n",
              "4    async def assert_response_is_brief_v1(example:...    True       True  \n",
              "5    async def assert_response_is_concise_v1(\\n    ...    True       True  \n",
              "6    async def assert_clear_professional_language_v...    True       True  \n",
              "7    async def assert_excludes_unrelated_topics_or_...    True       True  \n",
              "8    async def assert_excludes_full_codebase_review...    True       True  \n",
              "9    async def assert_response_does_not_require_ful...    True       True  \n",
              "42   async def assert_proper_acknowledgement_v1(exa...    True      False  \n",
              "43   async def assert_gratitude_personal_touch(exam...    True      False  \n",
              "858  async def assert_response_is_concise_v1(\\n    ...    True      False  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subsumption_results[subsumption_results[\"A -> B\"] == True]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the SPADE optimizer\n",
        "\n",
        "Ignore the MILP output for now. We will compare the output in a later cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the CBC MILP Solver \n",
            "Version: 2.10.3 \n",
            "Build Date: Dec 15 2019 \n",
            "\n",
            "command line - /Users/shreyashankar/miniforge3/envs/promptdelta/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/nq/ldkhrrws0xb9whw7b6rpzhc00000gn/T/1f69fc1155544fa1923afef33aa36b5c-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/nq/ldkhrrws0xb9whw7b6rpzhc00000gn/T/1f69fc1155544fa1923afef33aa36b5c-pulp.sol (default strategy 1)\n",
            "At line 2 NAME          MODEL\n",
            "At line 3 ROWS\n",
            "At line 6711 COLUMNS\n",
            "At line 25417 RHS\n",
            "At line 32124 BOUNDS\n",
            "At line 35605 ENDATA\n",
            "Problem MODEL has 6706 rows, 3480 columns and 11701 elements\n",
            "Coin0008I MODEL read with 0 errors\n",
            "Option for timeMode changed from cpu to elapsed\n",
            "Continuous objective value is 0.6 - 0.01 seconds\n",
            "Cgl0002I 1767 variables fixed\n",
            "Cgl0003I 24 fixed, 0 tightened bounds, 34 strengthened rows, 0 substitutions\n",
            "Cgl0004I processed model has 17 rows, 25 columns (25 integer (25 of which binary)) and 58 elements\n",
            "Cutoff increment increased from 1e-05 to 0.9999\n",
            "Cbc0038I Initial state - 5 integers unsatisfied sum - 0.5\n",
            "Cbc0038I Solution found of 2\n",
            "Cbc0038I Before mini branch and bound, 20 integers at bound fixed and 0 continuous\n",
            "Cbc0038I Mini branch and bound did not improve solution (0.04 seconds)\n",
            "Cbc0038I After 0.04 seconds - Feasibility pump exiting with objective of 2 - took 0.00 seconds\n",
            "Cbc0012I Integer solution of 2 found by feasibility pump after 0 iterations and 0 nodes (0.04 seconds)\n",
            "Cbc0001I Search completed - best objective 2, took 0 iterations and 0 nodes (0.04 seconds)\n",
            "Cbc0035I Maximum depth 0, 9 variables fixed on reduced cost\n",
            "Cuts at root node changed objective from 1.9 to 1.9\n",
            "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "\n",
            "Result - Optimal solution found\n",
            "\n",
            "Objective value:                2.00000000\n",
            "Enumerated nodes:               0\n",
            "Total iterations:               0\n",
            "Time (CPU seconds):             0.03\n",
            "Time (Wallclock seconds):       0.05\n",
            "\n",
            "Option for printingOptions changed from normal to all\n",
            "Total time (CPU seconds):       0.05   (Wallclock seconds):       0.07\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Solution Found:\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Solution Found:\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Selected Functions: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Selected Functions: \u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m22\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the CBC MILP Solver \n",
            "Version: 2.10.3 \n",
            "Build Date: Dec 15 2019 \n",
            "\n",
            "command line - /Users/shreyashankar/miniforge3/envs/promptdelta/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/nq/ldkhrrws0xb9whw7b6rpzhc00000gn/T/111a17bc6ed346feb587c2887b5db7eb-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/nq/ldkhrrws0xb9whw7b6rpzhc00000gn/T/111a17bc6ed346feb587c2887b5db7eb-pulp.sol (default strategy 1)\n",
            "At line 2 NAME          MODEL\n",
            "At line 3 ROWS\n",
            "At line 10715 COLUMNS\n",
            "At line 41446 RHS\n",
            "At line 52157 BOUNDS\n",
            "At line 57662 ENDATA\n",
            "Problem MODEL has 10710 rows, 5504 columns and 19678 elements\n",
            "Coin0008I MODEL read with 0 errors\n",
            "Option for timeMode changed from cpu to elapsed\n",
            "Continuous objective value is 18 - 0.01 seconds\n",
            "Cgl0002I 3725 variables fixed\n",
            "Cgl0003I 28 fixed, 0 tightened bounds, 0 strengthened rows, 4 substitutions\n",
            "Cgl0004I processed model has 19 rows, 15 columns (15 integer (15 of which binary)) and 45 elements\n",
            "Cutoff increment increased from 1e-05 to 0.9999\n",
            "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
            "Cbc0038I Solution found of 24\n",
            "Cbc0038I Before mini branch and bound, 15 integers at bound fixed and 0 continuous\n",
            "Cbc0038I Mini branch and bound did not improve solution (0.04 seconds)\n",
            "Cbc0038I After 0.04 seconds - Feasibility pump exiting with objective of 24 - took 0.00 seconds\n",
            "Cbc0012I Integer solution of 24 found by feasibility pump after 0 iterations and 0 nodes (0.04 seconds)\n",
            "Cbc0001I Search completed - best objective 24, took 0 iterations and 0 nodes (0.04 seconds)\n",
            "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
            "Cuts at root node changed objective from 24 to 24\n",
            "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
            "\n",
            "Result - Optimal solution found\n",
            "\n",
            "Objective value:                24.00000000\n",
            "Enumerated nodes:               0\n",
            "Total iterations:               0\n",
            "Time (CPU seconds):             0.04\n",
            "Time (Wallclock seconds):       0.05\n",
            "\n",
            "Option for printingOptions changed from normal to all\n",
            "Total time (CPU seconds):       0.07   (Wallclock seconds):       0.08\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Solution Found:\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Solution Found:\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Selected Functions: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Selected Functions: \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m9\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m14\u001b[0m, \u001b[1;36m18\u001b[0m, \u001b[1;36m21\u001b[0m, \u001b[1;36m22\u001b[0m, \u001b[1;36m30\u001b[0m, \u001b[1;36m31\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m38\u001b[0m, \u001b[1;36m42\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from spade.optimizer import select_functions\n",
        "\n",
        "optimizer_results = select_functions(f\"paper_experiments/{PIPELINE_NAME}/optimizer_input.pkl\", tau=0.25, alpha=0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare SPADE_base and SPADE_sub\n",
        "\n",
        "SPADE_base does not rely on the ILP; the result is constructed by throwing out any individual candidate assertions with FFR > threshold. SPADE_sub uses the ILP (with subsumption) to find the optimal set of assertions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">There are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> candidate assertions.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "There are \u001b[1;36m44\u001b[0m candidate assertions.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SPADE_base selected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> functions while SPADE_sub selected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> functions.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "SPADE_base selected \u001b[1;36m20\u001b[0m functions while SPADE_sub selected \u001b[1;36m15\u001b[0m functions.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SPADE_base had an FFR of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.11666666666666667</span> while SPADE_sub had an FFR of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.11666666666666667</span>. <span style=\"font-weight: bold\">(</span>Lower FFR is \n",
              "better.<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "SPADE_base had an FFR of \u001b[1;36m0.11666666666666667\u001b[0m while SPADE_sub had an FFR of \u001b[1;36m0.11666666666666667\u001b[0m. \u001b[1m(\u001b[0mLower FFR is \n",
              "better.\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SPADE_base had a coverage of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span> while SPADE_sub had a coverage of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.875</span>. <span style=\"font-weight: bold\">(</span>Higher coverage is better.<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "SPADE_base had a coverage of \u001b[1;36m1.0\u001b[0m while SPADE_sub had a coverage of \u001b[1;36m0.875\u001b[0m. \u001b[1m(\u001b[0mHigher coverage is better.\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SPADE_base excluded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> functions that are not subsumed and still satisfy FFR constraints while SPADE_sub excluded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> \n",
              "such functions.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "SPADE_base excluded \u001b[1;36m0\u001b[0m functions that are not subsumed and still satisfy FFR constraints while SPADE_sub excluded \u001b[1;36m0\u001b[0m \n",
              "such functions.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rprint(f\"There are {len(ALL_FUNCTIONS)} candidate assertions.\")\n",
        "rprint(f\"SPADE_base selected {len(optimizer_results['spade_base']['selected_functions'])} functions while SPADE_sub selected {len(optimizer_results['spade_sub']['selected_functions'])} functions.\")\n",
        "rprint(f\"SPADE_base had an FFR of {optimizer_results['spade_base']['ffr']} while SPADE_sub had an FFR of {optimizer_results['spade_sub']['ffr']}. (Lower FFR is better.)\")\n",
        "rprint(f\"SPADE_base had a coverage of {optimizer_results['spade_base']['coverage']} while SPADE_sub had a coverage of {optimizer_results['spade_sub']['coverage']}. (Higher coverage is better.)\")\n",
        "rprint(f\"SPADE_base excluded {len(optimizer_results['spade_base']['not_subsumed_excluded_functions'])} functions that are not subsumed and still satisfy FFR constraints while SPADE_sub excluded {len(optimizer_results['spade_sub']['not_subsumed_excluded_functions'])} such functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare SPADE_cov and SPADE_sub\n",
        "\n",
        "SPADE_cov uses the ILP but only optimizes for example coverage and FFR. SPADE_sub uses the ILP and optimizes for example coverage, FFR, and subsumption."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">There are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> candidate assertions.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "There are \u001b[1;36m44\u001b[0m candidate assertions.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SPADE_cov selected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> functions while SPADE_sub selected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> functions.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "SPADE_cov selected \u001b[1;36m2\u001b[0m functions while SPADE_sub selected \u001b[1;36m15\u001b[0m functions.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SPADE_cov had an FFR of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> while SPADE_sub had an FFR of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.11666666666666667</span>. <span style=\"font-weight: bold\">(</span>Lower FFR is better.<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "SPADE_cov had an FFR of \u001b[1;36m0.0\u001b[0m while SPADE_sub had an FFR of \u001b[1;36m0.11666666666666667\u001b[0m. \u001b[1m(\u001b[0mLower FFR is better.\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SPADE_cov had a coverage of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.625</span> while SPADE_sub had a coverage of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.875</span>. <span style=\"font-weight: bold\">(</span>Higher coverage is better.<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "SPADE_cov had a coverage of \u001b[1;36m0.625\u001b[0m while SPADE_sub had a coverage of \u001b[1;36m0.875\u001b[0m. \u001b[1m(\u001b[0mHigher coverage is better.\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SPADE_cov excluded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> functions that are not subsumed and still satisfy FFR constraints while SPADE_sub excluded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> \n",
              "such functions.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "SPADE_cov excluded \u001b[1;36m18\u001b[0m functions that are not subsumed and still satisfy FFR constraints while SPADE_sub excluded \u001b[1;36m0\u001b[0m \n",
              "such functions.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rprint(f\"There are {len(ALL_FUNCTIONS)} candidate assertions.\")\n",
        "rprint(f\"SPADE_cov selected {len(optimizer_results['spade_cov']['selected_functions'])} functions while SPADE_sub selected {len(optimizer_results['spade_sub']['selected_functions'])} functions.\")\n",
        "rprint(f\"SPADE_cov had an FFR of {optimizer_results['spade_cov']['ffr']} while SPADE_sub had an FFR of {optimizer_results['spade_sub']['ffr']}. (Lower FFR is better.)\")\n",
        "rprint(f\"SPADE_cov had a coverage of {optimizer_results['spade_cov']['coverage']} while SPADE_sub had a coverage of {optimizer_results['spade_sub']['coverage']}. (Higher coverage is better.)\")\n",
        "rprint(f\"SPADE_cov excluded {len(optimizer_results['spade_cov']['not_subsumed_excluded_functions'])} functions that are not subsumed and still satisfy FFR constraints while SPADE_sub excluded {len(optimizer_results['spade_sub']['not_subsumed_excluded_functions'])} such functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Print a sample of assertions selected by SPADE_sub but not SPADE_cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">async def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">assert_includes_code_improvement_v2</span><span style=\"font-weight: bold\">(</span>\n",
              "    example: dict, prompt: str, response: str\n",
              "<span style=\"font-weight: bold\">)</span>:\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    Check that the response includes suggestions for code improvements.\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    question = <span style=\"color: #008000; text-decoration-color: #008000\">\"Does the response include suggestions for code improvements?\"</span>\n",
              "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ask_llm</span><span style=\"font-weight: bold\">(</span>prompt, response, question<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "async def \u001b[1;35massert_includes_code_improvement_v2\u001b[0m\u001b[1m(\u001b[0m\n",
              "    example: dict, prompt: str, response: str\n",
              "\u001b[1m)\u001b[0m:\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    Check that the response includes suggestions for code improvements.\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    question = \u001b[32m\"Does the response include suggestions for code improvements?\"\u001b[0m\n",
              "    return await \u001b[1;35mask_llm\u001b[0m\u001b[1m(\u001b[0mprompt, response, question\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">async def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">assert_contains_brief_answers_v1</span><span style=\"font-weight: bold\">(</span>example: dict, prompt: str, response: str<span style=\"font-weight: bold\">)</span>:\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    Check that the response contains brief answers.\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    question = <span style=\"color: #008000; text-decoration-color: #008000\">\"Is the response brief and to the point without unnecessary elaboration?\"</span>\n",
              "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ask_llm</span><span style=\"font-weight: bold\">(</span>prompt, response, question<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "async def \u001b[1;35massert_contains_brief_answers_v1\u001b[0m\u001b[1m(\u001b[0mexample: dict, prompt: str, response: str\u001b[1m)\u001b[0m:\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    Check that the response contains brief answers.\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    question = \u001b[32m\"Is the response brief and to the point without unnecessary elaboration?\"\u001b[0m\n",
              "    return await \u001b[1;35mask_llm\u001b[0m\u001b[1m(\u001b[0mprompt, response, question\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">async def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">assert_consistency_with_tasks_and_instructions</span><span style=\"font-weight: bold\">(</span>\n",
              "    example: dict, prompt: str, response: str\n",
              "<span style=\"font-weight: bold\">)</span>:\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    Check if the response is consistent with the given tasks and instructions provided.\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
              "    question = <span style=\"color: #008000; text-decoration-color: #008000\">\"Is the response consistent with the tasks and instructions provided in the prompt template?\"</span>\n",
              "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ask_llm</span><span style=\"font-weight: bold\">(</span>prompt, response, question<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "async def \u001b[1;35massert_consistency_with_tasks_and_instructions\u001b[0m\u001b[1m(\u001b[0m\n",
              "    example: dict, prompt: str, response: str\n",
              "\u001b[1m)\u001b[0m:\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    Check if the response is consistent with the given tasks and instructions provided.\n",
              "    \u001b[32m\"\"\u001b[0m\"\n",
              "    question = \u001b[32m\"Is the response consistent with the tasks and instructions provided in the prompt template?\"\u001b[0m\n",
              "    return await \u001b[1;35mask_llm\u001b[0m\u001b[1m(\u001b[0mprompt, response, question\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get assertions in SPADE_sub but not in SPADE_cov\n",
        "unique_functions_in_sub = set(optimizer_results[\"spade_sub\"][\"selected_function_names\"]) - set(optimizer_results[\"spade_cov\"][\"selected_function_names\"])\n",
        "\n",
        "# Print 3 random assertions in unique_functions_in_sub\n",
        "import random\n",
        "random_assertions = list(unique_functions_in_sub)\n",
        "random_assertions = random.sample(random_assertions, 3)\n",
        "for assertion in random_assertions:\n",
        "    for f in ALL_FUNCTIONS:\n",
        "        if f.__name__ == assertion:\n",
        "            rprint(inspect.getsource(f))\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "promptdelta",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
