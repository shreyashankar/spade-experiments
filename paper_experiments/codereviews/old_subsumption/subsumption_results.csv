,func A,func B,A -> B,asked_LLM
0,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
2,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
3,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
4,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
5,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
6,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
7,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
8,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
9,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
10,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
11,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
12,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
13,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
14,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
15,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
16,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
17,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
18,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
19,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
20,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
21,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
22,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,True
23,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
24,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
25,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
26,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
27,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
28,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
29,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
30,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
31,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
32,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
33,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
34,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
35,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
36,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
37,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
38,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
39,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
40,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
41,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
42,"async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
43,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
44,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,True
45,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
46,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",True,True
47,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
48,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",True,True
49,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
50,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",True,True
51,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,True
52,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
53,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
54,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,True
55,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
56,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
57,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,True
58,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",True,True
59,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",True,True
60,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,True
61,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,True
62,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,True
63,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
64,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",True,True
65,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
66,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",True,True
67,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,True
68,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",True,True
69,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
70,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
71,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",True,True
72,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",True,True
73,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",True,True
74,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",True,True
75,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
76,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
77,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
78,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
79,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
80,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",True,True
81,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
82,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
83,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",True,True
84,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",True,True
85,"async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",True,True
86,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
87,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",True,True
88,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
89,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",True,True
90,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
91,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,True
92,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,True
93,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,True
94,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",True,True
95,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,True
96,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
97,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",True,True
98,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
99,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
100,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,True
101,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",True,True
102,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",True,True
103,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",True,True
104,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,True
105,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",True,True
106,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
107,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",True,True
108,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,True
109,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",True,True
110,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,True
111,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",True,True
112,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
113,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,True
114,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,True
115,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,True
116,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
117,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,True
118,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
119,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
120,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
121,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
122,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
123,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",True,True
124,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,True
125,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
126,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",True,True
127,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",True,True
128,"async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,True
129,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
130,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
131,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
132,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
133,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
134,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
135,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
136,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
137,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
138,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
139,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
140,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
141,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
142,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
143,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
144,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
145,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
146,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
147,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
148,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
149,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
150,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
151,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
152,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
153,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
154,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
155,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
156,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
157,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
158,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
159,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
160,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
161,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
162,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
163,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
164,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
165,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
166,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
167,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
168,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
169,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
170,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
171,"async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
172,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
173,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
174,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
175,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
176,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
177,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
178,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
179,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
180,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
181,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
182,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
183,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
184,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
185,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
186,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
187,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
188,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
189,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
190,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
191,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
192,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
193,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
194,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
195,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
196,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
197,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
198,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
199,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
200,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
201,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
202,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",True,True
203,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
204,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
205,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
206,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
207,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
208,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
209,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
210,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
211,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,True
212,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
213,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
214,"async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
215,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
216,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
217,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
218,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
219,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
220,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
221,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
222,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
223,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
224,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
225,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
226,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
227,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
228,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
229,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
230,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
231,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
232,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
233,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
234,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
235,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
236,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
237,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
238,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
239,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
240,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
241,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
242,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
243,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
244,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
245,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
246,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
247,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
248,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
249,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
250,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
251,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
252,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
253,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
254,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
255,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
256,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
257,"async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
258,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
259,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
260,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
261,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
262,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
263,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
264,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
265,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
266,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
267,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
268,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
269,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
270,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
271,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
272,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
273,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
274,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
275,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
276,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
277,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
278,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
279,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
280,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,True
281,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
282,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
283,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
284,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
285,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
286,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
287,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
288,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
289,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
290,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
291,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,True
292,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
293,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
294,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
295,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
296,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,True
297,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,True
298,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
299,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
300,"async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
301,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
302,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
303,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
304,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
305,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
306,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
307,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
308,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
309,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
310,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
311,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
312,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
313,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
314,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
315,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
316,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
317,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
318,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
319,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
320,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
321,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
322,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
323,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
324,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
325,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
326,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
327,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
328,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
329,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
330,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
331,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
332,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
333,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
334,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
335,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
336,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
337,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
338,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
339,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
340,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
341,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
342,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
343,"async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
344,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
345,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
346,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
347,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
348,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
349,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
350,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
351,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,True
352,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
353,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
354,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
355,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
356,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
357,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
358,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
359,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
360,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
361,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
362,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
363,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
364,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",True,True
365,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
366,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
367,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
368,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
369,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
370,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
371,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
372,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
373,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
374,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",True,True
375,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
376,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
377,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
378,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
379,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
380,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
381,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
382,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
383,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
384,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
385,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
386,"async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
387,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
388,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
389,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
390,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,True
391,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
392,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
393,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
394,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
395,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",True,True
396,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
397,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
398,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
399,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
400,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
401,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
402,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
403,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
404,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
405,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
406,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
407,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
408,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
409,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,True
410,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
411,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
412,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
413,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,True
414,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
415,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
416,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
417,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
418,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
419,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
420,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,True
421,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
422,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
423,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
424,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
425,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
426,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
427,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
428,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
429,"async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
430,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
431,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
432,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
433,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
434,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
435,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
436,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
437,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
438,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
439,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
440,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
441,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
442,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
443,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
444,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
445,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
446,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
447,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
448,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
449,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
450,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
451,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
452,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
453,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
454,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
455,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
456,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
457,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
458,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
459,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
460,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
461,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
462,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
463,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
464,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
465,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
466,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
467,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
468,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
469,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
470,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
471,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
472,"async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
473,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
474,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
475,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
476,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
477,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
478,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
479,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
480,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
481,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
482,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
483,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
484,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
485,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
486,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
487,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
488,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
489,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
490,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
491,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
492,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
493,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
494,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
495,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
496,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
497,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
498,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
499,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
500,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
501,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
502,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
503,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
504,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
505,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
506,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
507,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
508,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
509,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
510,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
511,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
512,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,True
513,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
514,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
515,"async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
516,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
517,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
518,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
519,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
520,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
521,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
522,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,True
523,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
524,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
525,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
526,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
527,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
528,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
529,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
530,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
531,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
532,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
533,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
534,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
535,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
536,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
537,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
538,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,True
539,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
540,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
541,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
542,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,True
543,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,True
544,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
545,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
546,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
547,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
548,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
549,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,True
550,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
551,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,True
552,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
553,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
554,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
555,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,True
556,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
557,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
558,"async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
559,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
560,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
561,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
562,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
563,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
564,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
565,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
566,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
567,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
568,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
569,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
570,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
571,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
572,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
573,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
574,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
575,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
576,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
577,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
578,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
579,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
580,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
581,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
582,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
583,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
584,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
585,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
586,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
587,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
588,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
589,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
590,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
591,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
592,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
593,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
594,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
595,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
596,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
597,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
598,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
599,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
600,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
601,"async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
602,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
603,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
604,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
605,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
606,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
607,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
608,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
609,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
610,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
611,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
612,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
613,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
614,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
615,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
616,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
617,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
618,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
619,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
620,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
621,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
622,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
623,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
624,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
625,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
626,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
627,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
628,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
629,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
630,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
631,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
632,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
633,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
634,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
635,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
636,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
637,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
638,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
639,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
640,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
641,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
642,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
643,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
644,"async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
645,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
646,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",True,True
647,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",True,True
648,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
649,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",True,True
650,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
651,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",True,True
652,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
653,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,True
654,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",True,True
655,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
656,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
657,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,True
658,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
659,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
660,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",True,True
661,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",True,True
662,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",True,True
663,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",True,True
664,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",True,True
665,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
666,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",True,True
667,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
668,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",True,True
669,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",True,True
670,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",True,True
671,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
672,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
673,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",True,True
674,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",True,True
675,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",True,True
676,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",True,True
677,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
678,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
679,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
680,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
681,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
682,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,True
683,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
684,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
685,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",True,True
686,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",True,True
687,"async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",True,True
688,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,True
689,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
690,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
691,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
692,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
693,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
694,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
695,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
696,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
697,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
698,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
699,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
700,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
701,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
702,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
703,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
704,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
705,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
706,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
707,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
708,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
709,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
710,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
711,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
712,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
713,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
714,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,True
715,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
716,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
717,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
718,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
719,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
720,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
721,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
722,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
723,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
724,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
725,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
726,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
727,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,True
728,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
729,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",True,True
730,"async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
731,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
732,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
733,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
734,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
735,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
736,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
737,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
738,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
739,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
740,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
741,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
742,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
743,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
744,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
745,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
746,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
747,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
748,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
749,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
750,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
751,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
752,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
753,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
754,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
755,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
756,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
757,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
758,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
759,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
760,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
761,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",True,True
762,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
763,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
764,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
765,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
766,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
767,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
768,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
769,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
770,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
771,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
772,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
773,"async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
774,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
775,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
776,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
777,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
778,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
779,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
780,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
781,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
782,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
783,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
784,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
785,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
786,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
787,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
788,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
789,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
790,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
791,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
792,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
793,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
794,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
795,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
796,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
797,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
798,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
799,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
800,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
801,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
802,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
803,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
804,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
805,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
806,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
807,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
808,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
809,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
810,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
811,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
812,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
813,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
814,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
815,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",True,True
816,"async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
817,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
818,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
819,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
820,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
821,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
822,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
823,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
824,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
825,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
826,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
827,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
828,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
829,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
830,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
831,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
832,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
833,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
834,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
835,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
836,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
837,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
838,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
839,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
840,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
841,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
842,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
843,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
844,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
845,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
846,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
847,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
848,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
849,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
850,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
851,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
852,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
853,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
854,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
855,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
856,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
857,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
858,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
859,"async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
860,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
861,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",True,True
862,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",True,True
863,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
864,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
865,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
866,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",True,True
867,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
868,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",True,True
869,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",True,True
870,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
871,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
872,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",True,True
873,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
874,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
875,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",True,True
876,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",True,True
877,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
878,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",True,True
879,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
880,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",True,True
881,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",True,True
882,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
883,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
884,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",True,True
885,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",True,True
886,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
887,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
888,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",True,True
889,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",True,True
890,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",True,True
891,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
892,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
893,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
894,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
895,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
896,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
897,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",True,True
898,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
899,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
900,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
901,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
902,"async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",True,True
903,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
904,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
905,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
906,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
907,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
908,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
909,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
910,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,True
911,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
912,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
913,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,True
914,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
915,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
916,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
917,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
918,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
919,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
920,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
921,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
922,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
923,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
924,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
925,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
926,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
927,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
928,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
929,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
930,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
931,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
932,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
933,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
934,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
935,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
936,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
937,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
938,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,True
939,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
940,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
941,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
942,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
943,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
944,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
945,"async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
946,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,True
947,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,True
948,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,True
949,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
950,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",True,True
951,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
952,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,True
953,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
954,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",True,True
955,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,True
956,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
957,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
958,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,True
959,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
960,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
961,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,True
962,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,True
963,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",True,True
964,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,True
965,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,True
966,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,True
967,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
968,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
969,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",True,True
970,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",True,True
971,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",True,True
972,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
973,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,True
974,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",True,True
975,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,True
976,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
977,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,True
978,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,True
979,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
980,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
981,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
982,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
983,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,True
984,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,True
985,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
986,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",True,True
987,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,True
988,"async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",True,True
989,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
990,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
991,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
992,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
993,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
994,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
995,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
996,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
997,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
998,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
999,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1000,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1001,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1002,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1003,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1004,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1005,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1006,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1007,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1008,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1009,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1010,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1011,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1012,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1013,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1014,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1015,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1016,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1017,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1018,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1019,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1020,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1021,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1022,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1023,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1024,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1025,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1026,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1027,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1028,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1029,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1030,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1031,"async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1032,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1033,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1034,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1035,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1036,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1037,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1038,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1039,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1040,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1041,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1042,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1043,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1044,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1045,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1046,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1047,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1048,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1049,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1050,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1051,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1052,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1053,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",True,True
1054,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1055,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1056,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1057,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1058,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1059,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1060,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1061,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1062,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",True,True
1063,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1064,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1065,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1066,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1067,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1068,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1069,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1070,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1071,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1072,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1073,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1074,"async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1075,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
1076,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,True
1077,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",True,True
1078,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
1079,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,True
1080,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1081,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,True
1082,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
1083,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,True
1084,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,True
1085,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,True
1086,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
1087,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,True
1088,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1089,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1090,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,True
1091,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,True
1092,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",True,True
1093,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,True
1094,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",True,True
1095,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,True
1096,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
1097,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,True
1098,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
1099,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1100,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,True
1101,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,True
1102,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
1103,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,True
1104,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",True,True
1105,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
1106,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",True,True
1107,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
1108,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
1109,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1110,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,True
1111,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
1112,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",True,True
1113,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1114,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
1115,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",True,True
1116,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,True
1117,"async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,True
1118,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,True
1119,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,True
1120,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,True
1121,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,True
1122,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",True,True
1123,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
1124,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,True
1125,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
1126,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,True
1127,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,True
1128,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
1129,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
1130,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,True
1131,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1132,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1133,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,True
1134,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,True
1135,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,True
1136,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",True,True
1137,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",True,True
1138,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",True,True
1139,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",True,True
1140,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,True
1141,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
1142,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1143,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,True
1144,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
1145,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
1146,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,True
1147,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",True,True
1148,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",True,True
1149,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",True,True
1150,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
1151,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
1152,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1153,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
1154,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
1155,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",True,True
1156,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,True
1157,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
1158,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",True,True
1159,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,True
1160,"async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",True,True
1161,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1162,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1163,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1164,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1165,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1166,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1167,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1168,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
1169,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1170,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1171,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
1172,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1173,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1174,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1175,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
1176,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1177,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1178,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1179,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1180,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1181,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1182,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1183,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1184,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
1185,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1186,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1187,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1188,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1189,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1190,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1191,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1192,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1193,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
1194,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
1195,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1196,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
1197,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1198,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1199,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1200,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1201,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1202,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1203,"async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1204,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1205,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1206,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1207,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1208,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1209,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1210,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1211,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1212,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1213,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1214,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1215,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1216,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1217,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1218,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1219,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1220,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1221,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1222,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1223,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1224,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1225,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1226,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1227,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1228,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1229,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1230,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1231,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1232,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1233,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1234,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1235,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1236,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1237,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1238,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1239,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1240,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1241,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1242,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1243,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1244,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1245,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1246,"async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1247,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,True
1248,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1249,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1250,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1251,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1252,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
1253,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1254,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,True
1255,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1256,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1257,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
1258,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
1259,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1260,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,True
1261,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1262,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1263,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1264,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1265,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1266,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",True,True
1267,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1268,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
1269,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1270,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
1271,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1272,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1273,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1274,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
1275,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1276,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1277,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
1278,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",True,True
1279,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
1280,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
1281,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1282,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
1283,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
1284,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1285,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1286,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,True
1287,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1288,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1289,"async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1290,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
1291,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,True
1292,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",True,True
1293,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
1294,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",True,True
1295,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
1296,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,True
1297,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
1298,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",True,True
1299,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,True
1300,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
1301,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
1302,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",True,True
1303,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1304,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1305,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",True,True
1306,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,True
1307,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",True,True
1308,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",True,True
1309,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",True,True
1310,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",True,True
1311,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",True,True
1312,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",True,True
1313,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
1314,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1315,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,True
1316,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",True,True
1317,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
1318,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,True
1319,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",True,True
1320,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",True,True
1321,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",True,True
1322,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
1323,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
1324,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1325,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
1326,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
1327,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",True,True
1328,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1329,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,True
1330,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",True,True
1331,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",True,True
1332,"async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,True
1333,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1334,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1335,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1336,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1337,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1338,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1339,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1340,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
1341,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1342,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1343,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
1344,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1345,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1346,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1347,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1348,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1349,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1350,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1351,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1352,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1353,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1354,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1355,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1356,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
1357,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1358,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1359,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1360,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1361,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1362,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1363,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1364,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1365,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
1366,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
1367,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1368,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
1369,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1370,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1371,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1372,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1373,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1374,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1375,"async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1376,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1377,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1378,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1379,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1380,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1381,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1382,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1383,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1384,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1385,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1386,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1387,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1388,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1389,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1390,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1391,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1392,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1393,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1394,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1395,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1396,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1397,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1398,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1399,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1400,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1401,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1402,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1403,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1404,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1405,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1406,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1407,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1408,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1409,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1410,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1411,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1412,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1413,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1414,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1415,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1416,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1417,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1418,"async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1419,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1420,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1421,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1422,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1423,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1424,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1425,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1426,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1427,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1428,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1429,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1430,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1431,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1432,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1433,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1434,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1435,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1436,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1437,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1438,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1439,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1440,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1441,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1442,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1443,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1444,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1445,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1446,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1447,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1448,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1449,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1450,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1451,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1452,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1453,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1454,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1455,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1456,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1457,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1458,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1459,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1460,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1461,"async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1462,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1463,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1464,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1465,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1466,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1467,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1468,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1469,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1470,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1471,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1472,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1473,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1474,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1475,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1476,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1477,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1478,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1479,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1480,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1481,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1482,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1483,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1484,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1485,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1486,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1487,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1488,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1489,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1490,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1491,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1492,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1493,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1494,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1495,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1496,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1497,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1498,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1499,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1500,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1501,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1502,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1503,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1504,"async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1505,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1506,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1507,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1508,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1509,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1510,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1511,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1512,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1513,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1514,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1515,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1516,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1517,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1518,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1519,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1520,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1521,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1522,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1523,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1524,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1525,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1526,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1527,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1528,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1529,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1530,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1531,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1532,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1533,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1534,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1535,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1536,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1537,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1538,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1539,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1540,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1541,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1542,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1543,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1544,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1545,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1546,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1547,"async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1548,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1549,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1550,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1551,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1552,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1553,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1554,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1555,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1556,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1557,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1558,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1559,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1560,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1561,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1562,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1563,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1564,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1565,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1566,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1567,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1568,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1569,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1570,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1571,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1572,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1573,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1574,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1575,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1576,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1577,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1578,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1579,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1580,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1581,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1582,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1583,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1584,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1585,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1586,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1587,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1588,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1589,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1590,"async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1591,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1592,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1593,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1594,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1595,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1596,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1597,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1598,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1599,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1600,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1601,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1602,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1603,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1604,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1605,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1606,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1607,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1608,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1609,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1610,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1611,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1612,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",True,True
1613,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1614,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1615,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1616,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1617,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1618,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1619,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1620,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1621,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1622,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1623,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1624,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1625,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1626,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1627,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1628,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1629,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1630,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1631,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1632,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1633,"async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1634,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
1635,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,True
1636,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,True
1637,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
1638,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",True,True
1639,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1640,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,True
1641,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,True
1642,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",True,True
1643,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",True,True
1644,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
1645,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
1646,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,True
1647,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,True
1648,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1649,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",True,True
1650,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,True
1651,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",True,True
1652,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,True
1653,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",True,True
1654,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",True,True
1655,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,True
1656,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,True
1657,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,True
1658,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1659,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",True,True
1660,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,True
1661,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,True
1662,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
1663,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,True
1664,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,True
1665,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
1666,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,True
1667,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
1668,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
1669,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1670,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,True
1671,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
1672,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1673,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",True,True
1674,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",True,True
1675,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",True,True
1676,"async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",True,True
1677,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1678,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1679,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1680,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1681,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1682,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1683,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1684,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1685,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1686,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1687,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1688,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1689,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1690,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1691,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1692,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1693,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1694,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1695,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1696,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1697,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1698,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1699,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1700,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1701,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1702,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1703,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1704,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1705,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1706,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1707,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1708,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1709,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1710,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1711,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1712,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1713,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1714,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1715,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1716,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1717,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1718,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1719,"async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1720,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1721,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1722,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1723,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1724,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1725,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1726,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1727,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
1728,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1729,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1730,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
1731,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1732,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1733,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1734,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
1735,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1736,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1737,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1738,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1739,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1740,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1741,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1742,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1743,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
1744,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1745,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1746,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1747,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1748,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1749,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1750,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1751,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1752,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1753,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
1754,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,True
1755,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,True
1756,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,True
1757,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1758,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1759,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1760,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1761,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1762,"async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1763,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,True
1764,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",True,True
1765,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",True,True
1766,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1767,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1768,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1769,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",True,True
1770,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1771,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",True,True
1772,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",True,True
1773,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1774,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1775,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,True
1776,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1777,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1778,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",True,True
1779,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,True
1780,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1781,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,True
1782,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1783,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1784,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",True,True
1785,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",True,True
1786,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1787,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1788,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",True,True
1789,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",True,True
1790,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
1791,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1792,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,True
1793,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",True,True
1794,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
1795,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1796,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1797,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1798,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1799,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1800,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1801,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",True,True
1802,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1803,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,True
1804,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",False,False
1805,"async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",True,True
1806,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",False,False
1807,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",False,False
1808,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",False,False
1809,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",False,False
1810,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",False,False
1811,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1812,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,False
1813,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",False,False
1814,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,False
1815,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",False,False
1816,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",False,False
1817,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",False,False
1818,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,False
1819,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1820,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1821,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",False,False
1822,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,False
1823,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",False,False
1824,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,False
1825,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",False,False
1826,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",False,False
1827,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",False,False
1828,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",False,False
1829,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",False,False
1830,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1831,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",False,False
1832,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,False
1833,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",False,False
1834,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",False,False
1835,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",False,False
1836,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",False,False
1837,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,False
1838,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",False,False
1839,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",False,False
1840,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",False,False
1841,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",False,False
1842,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",False,False
1843,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",False,False
1844,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",False,False
1845,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",False,False
1846,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,False
1847,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",False,False
1848,"async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
","async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
",False,False
1849,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_includes_code_improvements_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes code improvement suggestions.
    """"""
    # It's expected that the response must contain the word ""improvement"" or modifications in the code snippet
    improvements_keywords = [""improvement"", ""improve"", ""refactor""]
    return any(keyword in response for keyword in improvements_keywords)
",True,True
1850,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_follows_review_format_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response follows a specific format resembling a code review,
    which includes a title, author mention, gratitude, and listed improvements.
    """"""
    response_lines = response.split(""\n"")
    has_title = any(""Title:"" in line for line in response_lines)
    has_author = example[""author""] in response
    has_gratitude = ""thank you"" in response.lower() or ""thanks"" in response.lower()
    has_improvements = ""Improvements:"" in response or ""improvement:"" in response.lower()

    return has_title and has_author and has_gratitude and has_improvements
",True,True
1851,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_examples_of_improvement_follow_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the examples of improvements in the response follow the code conventions
    of the language (Python in this case), checking for syntax correctness.
    """"""
    # Example Python code to check for syntax errors in response
    try:
        exec(response)
    except SyntaxError:
        return False
    return True
",True,True
1852,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_adheres_to_workflow_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response adheres to the workflow of discussing only the code in the diff,
    with no assumptions or extrapolations outside of the provided code segment.
    """"""
    question = ""Does the response adhere to the workflow by discussing the code diff without making assumptions about the unseen code?""
    return await ask_llm(prompt, response, question)
",True,True
1853,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_recognition_of_code_conventions_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response includes recognition of the coding conventions, such as the use of snake_case for function names in Python.
    """"""
    question = ""Does the response recognize and adhere to the code conventions of Python, including proper naming and style?""
    return await ask_llm(prompt, response, question)
",True,True
1854,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_exclusion_of_speculation_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response does not include speculations or assumptions about the parts of the code that are not visible in the diff.
    """"""
    question = ""Does the response avoid making speculations or assumptions about the unseen parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1855,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_is_personal_and_grateful_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response demonstrates a personal touch and shows gratitude towards the author of the pull request.
    """"""
    is_personal = example[""author""] in response
    shows_gratitude = (
        ""thank you"" in response.lower() or ""gratitude:"" in response.lower()
    )
    return is_personal and shows_gratitude
",False,True
1856,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_is_concise_v1(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response is concise and to the point, without unnecessary elaboration.
    """"""
    question = ""Is the LLM response concise and to the point?""
    return await ask_llm(prompt, response, question)
",True,True
1857,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_includes_code_review_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a code review of the changes fetched
    via the get_diff function.
    """"""
    code_review_present = ""Review:"" in response or ""Improvement:"" in response
    return code_review_present
",False,True
1858,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_includes_improvements_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response answers on what can be improved and provides the
    improvement in code.
    """"""
    contains_improvement = ""Improvement:"" in response
    return contains_improvement
",True,True
1859,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_is_brief_v1(example: dict, prompt: str, response: str):
    """"""
    Assess if the response possesses a certain brevity as verbose commentary is discouraged.
    """"""
    question = ""Is the review in the response brief and to the point without unnecessary verbosity?""
    return await ask_llm(prompt, response, question)
",True,True
1860,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_follows_code_conventions_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows code conventions of the language it is reviewing.
    """"""
    question = ""Does the response follow Python's code conventions?""
    return await ask_llm(prompt, response, question)
",True,True
1861,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_is_personal_and_grateful_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes a personal tone and shows gratitude to the author of the pull request.
    """"""
    is_personal = ""Thank you, @"" in response or ""Great work!"" in response
    return is_personal
",False,True
1862,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_does_not_require_full_code_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the response does not indicate a need for access to the full code.
    """"""
    question = (
        ""Does the response provide a review without requiring access to the full code?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1863,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_review_based_on_workflow_v1(example: dict, prompt: str, response: str):
    """"""
    Confirm that the response indicates that the review process was based on the workflow described in the template.
    """"""
    # Since the workflow description does not directly reflect in the output, we ask the LLM.
    question = (
        ""Was the review in the response based on the workflow described in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1864,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_presentation_format_v1(example: dict, prompt: str, response: str):
    """"""
    Verify if the LLM response includes instructions within a structured format.
    """"""
    if (
        ""Instructions"" in response
        and ""Improvements:"" in response
        and ""Code Review:"" in response
    ):
        return True
    else:
        return False
",True,True
1865,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_improvement_suggestion_v1(example: dict, prompt: str, response: str):
    """"""
    Check whether the response provides an improvement in code or a suggestion for improvement.
    """"""
    return ""Improvements:"" in response
",False,True
1866,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_workflow_adherence_v1(example: dict, prompt: str, response: str):
    """"""
    Check if the LLM has reviewed the code based on the diff_url following the instructions.
    """"""
    # This might be ambiguous without the full context of diff_url, hence using ask_llm
    question = ""Does the response show that the review was based on the diff_url provided, following the instructions given?""
    return await ask_llm(prompt, response, question)
",True,True
1867,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_code_review_aspects(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes different aspects of code review: code snippets,
    adherence to language conventions, and a personal touch.
    """"""
    includes_code_snippets = ""```python"" in response and ""```"" in response
    personal_touch = ""@"" + example.get(""author"", """").replace(""@"", """") in response
    return includes_code_snippets and personal_touch
",False,True
1868,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_properly_structured_english_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is in sentence or paragraph form with properly structured English.
    """"""
    question = ""Is the response in sentence or paragraph form with properly structured English?""
    return await ask_llm(prompt, response, question)
",True,True
1869,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_includes_get_diff_usage_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response includes an explanation or demonstration of how to use the 'get_diff' function.
    """"""
    # Since the response content can be varied and complex, using ask_llm to evaluate
    return await ask_llm(
        prompt,
        response,
        ""Does the response explain or demonstrate how to use the 'get_diff' function?"",
    )
",True,True
1870,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_excludes_irrelevant_content_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response excludes any keywords or steps not related to the pull request review process.
    """"""
    irrelevant_terms = [""irrelevant"", ""unnecessary"", ""unrelated""]
    # This can use Python string methods since it's a check for the exclusion of certain terms
    return not any(term in response for term in irrelevant_terms)
",True,True
1871,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_has_pull_request_keywords_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response always includes essential keywords related to pull request review.
    """"""
    # Keywords to be present in the response
    keywords = [""pull request"", ""code changes"", ""diff_url"", ""get_diff""]
    # This can be evaluated directly in Python since it's just a presence check
    return all(keyword in response for keyword in keywords)
",True,True
1872,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_clear_professional_language_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is professional, clear, and without unnecessary jargon or overly complex vocabulary.
    """"""
    question = ""Is the response professional, clear, and without unnecessary jargon or overly complex vocabulary?""
    return await ask_llm(prompt, response, question)
",True,True
1873,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_follows_workflow_steps_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response follows the exact steps or sequence provided in the workflow.
    """"""
    # This assessment is complex and requires contextual understanding, so ask_llm is appropriate
    question = (
        ""Does the response follow the exact steps or sequence provided in the workflow?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1874,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_proper_acknowledgement_v1(example: dict, prompt: str, response: str):
    """"""
    Check for proper personal acknowledgement and gratitude towards the pull request author.
    """"""
    # Check for the ""@"" symbol followed by a username (author) and words expressing gratitude
    # We assume the author name will not contain spaces
    author = example.get(""author"")
    gratitude_phrases = [""thank you"", ""thanks"", ""appreciate"", ""grateful""]
    return (
        any(gratitude in response for gratitude in gratitude_phrases)
        and f""@{author}"" in response
    )
",True,True
1875,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_includes_improvements_and_code_snippets(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes both suggestions for improvements and corresponding code snippets.
    """"""
    return (
        ""```"" in response
        and ""def "" in response
        and all(term in response for term in [""->"", ""self.result"", ""return""])
    )
",False,True
1876,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_excludes_full_codebase_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not attempt to review code outside of the given code diff.
    """"""
    # Assuming that non-diff related comments would not start with 'def ' or include 'self.' keywords
    code_diff_terms = [""def "", ""self.""]
    # If all code-related terms in the response also appear in the code diff, assume no full codebase review
    return all(
        term in example[""diff""][0][""additions""]
        for term in code_diff_terms
        if term in response
    )
",True,True
1877,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_response_is_concise_and_clear(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response is concise and clear.
    """"""
    question = ""Is this pull request review response concise and clear?""
    return await ask_llm(prompt, response, question)
",True,True
1878,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_reference_to_pull_request_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is in reference to a pull request review.
    """"""
    return (
        ""@pythonDev"" in response
        and ""suggestion"" in response.lower()
        and ""pull request"" in response.lower()
    )
",True,True
1879,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_follows_instructions_for_review(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response follows the given instructions for providing a review.
    """"""
    instructions = [
        ""you don’t have access to the full code but only the code diff"",
        ""make it personal"",
        'always show gratitude to the author using ""@"" when tagging',
        ""Include code snippets if necessary"",
        ""Adhere to the languages code conventions"",
    ]
    return all(instruction in prompt for instruction in instructions)
",True,True
1880,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_excludes_unrelated_topics_or_keywords(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not mention any unrelated topics or keywords.
    """"""
    unrelated_terms = [""AI Assistant"", ""expert"", ""reviewing pull requests""]
    return not any(unrelated_term in response for unrelated_term in unrelated_terms)
",False,True
1881,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_completeness_in_reviewing_code_diff(
    example: dict, prompt: str, response: str
):
    """"""
    Ask LLM if the response demonstrates completeness in reviewing only the code diff provided.
    """"""
    question = ""Does this response demonstrate completeness in reviewing only the code diff provided?""
    return await ask_llm(prompt, response, question)
",True,True
1882,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_consistency_with_tasks_and_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is consistent with the given tasks and instructions provided.
    """"""
    question = ""Is the response consistent with the tasks and instructions provided in the prompt template?""
    return await ask_llm(prompt, response, question)
",True,True
1883,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_includes_code_improvement_v2(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response includes suggestions for code improvements.
    """"""
    question = ""Does the response include suggestions for code improvements?""
    return await ask_llm(prompt, response, question)
",True,True
1884,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_respects_information_limitation_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response respects the limitation of information
    and does not refer to non-available parts of the code.
    """"""
    question = ""Does the response correctly avoid referring to non-available parts of the code?""
    return await ask_llm(prompt, response, question)
",True,True
1885,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_contains_brief_answers_v1(example: dict, prompt: str, response: str):
    """"""
    Check that the response contains brief answers.
    """"""
    question = ""Is the response brief and to the point without unnecessary elaboration?""
    return await ask_llm(prompt, response, question)
",True,True
1886,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_correctly_explains_diff_format_v1(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response explains the code diff format correctly.
    """"""
    question = ""Does the response correctly explain the code diff format using '+' and '-' symbols?""
    return await ask_llm(prompt, response, question)
",True,True
1887,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_excludes_irrelevant_code(example: dict, prompt: str, response: str):
    """"""
    Check that the response does not include code that hasn't been added or removed.
    """"""
    additions = """".join(diff[""additions""] for diff in example[""diff""])
    deletions = """".join(diff[""deletions""] for diff in example[""diff""])

    # Convert code blocks to plain text for comparison.
    response_code = """".join(response.split(""```"")[1::2]).strip()

    # Check if the code in the response is strictly from the additions or deletions.
    return additions.strip() in response_code and deletions.strip() in response_code
",True,True
1888,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_responds_to_correct_pull_request(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the response is a review of the received Pull Request (PR) and not any other topic.
    """"""
    pr_title = example[""title""]
    question = (
        f""Is the response a review focused on the Pull Request titled '{pr_title}'?""
    )
    return await ask_llm(prompt, response, question)
",True,True
1889,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_gratitude_personal_touch(example: dict, prompt: str, response: str):
    """"""
    Ensure that response includes gratitude towards the author in a personal manner, possibly by tagging them.
    """"""
    author_tag = ""@"" + example.get(""author"", """").replace(""@"", """")
    return author_tag in response
",False,True
1890,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_exclusion_of_full_code(example: dict, prompt: str, response: str):
    """"""
    Verify that the response does not demonstrate access to the full code, only the code diff.
    """"""
    question = ""Does the response give the impression that the full code was accessed instead of just the code diff?""
    return not await ask_llm(prompt, response, question)
",True,True
1891,"async def assert_correct_payload_integration(example: dict, prompt: str, response: str):
    """"""
    Ensure that the response correctly interprets and integrates the pr_webhook_payload.
    """"""
    # Since this is likely factual, it can be inferred from response contents using Python's string methods
    has_title = example[""title""] in response
    has_description = example[""description""] in response

    return has_title and has_description
","async def assert_conciseness_and_convention(example: dict, prompt: str, response: str):
    """"""
    Check that the response is concise and adheres to the language code conventions.
    """"""
    question_for_conciseness = ""Is the response concise?""
    question_for_convention = (
        ""Does the response adhere to the language's code conventions?""
    )

    # Call ask_llm once for brevity since both are qualitative assessments
    concise = await ask_llm(prompt, response, question_for_conciseness)
    convention = await ask_llm(prompt, response, question_for_convention)

    return concise and convention
",True,True
