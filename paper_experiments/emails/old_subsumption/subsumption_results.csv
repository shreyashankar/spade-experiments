,func A,func B,A -> B,asked_LLM
0,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,True
1,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,True
2,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,True
3,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,True
4,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,True
5,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,True
6,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,True
7,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",True,True
8,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,True
9,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,True
10,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",True,True
11,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",True,True
12,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
13,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,True
14,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,True
15,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",True,True
16,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,True
17,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,True
18,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",True,True
19,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,True
20,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",True,True
21,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
22,"async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",True,True
23,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
24,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
25,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
26,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
27,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
28,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
29,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
30,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
31,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
32,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
33,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
34,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
35,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
36,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
37,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
38,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
39,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
40,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
41,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
42,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
43,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
44,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
45,"async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
46,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",True,True
47,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",True,True
48,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",True,True
49,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",True,True
50,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,True
51,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,True
52,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,True
53,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,True
54,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",True,True
55,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,True
56,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,True
57,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,True
58,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
59,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,True
60,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,True
61,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,True
62,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,True
63,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
64,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",True,True
65,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,True
66,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",True,True
67,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,True
68,"async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,True
69,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
70,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
71,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
72,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
73,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
74,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
75,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
76,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
77,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
78,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
79,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
80,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
81,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
82,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
83,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
84,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
85,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
86,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
87,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
88,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
89,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
90,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
91,"async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
92,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
93,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",True,True
94,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
95,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,True
96,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,True
97,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,True
98,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,True
99,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
100,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
101,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
102,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
103,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
104,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
105,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,True
106,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
107,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,True
108,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",True,True
109,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
110,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",True,True
111,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,True
112,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
113,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
114,"async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,True
115,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
116,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
117,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
118,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
119,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
120,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
121,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
122,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
123,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
124,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
125,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
126,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
127,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
128,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
129,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
130,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
131,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
132,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
133,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
134,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
135,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
136,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
137,"async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
138,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
139,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
140,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
141,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
142,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
143,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
144,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
145,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
146,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
147,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
148,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
149,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
150,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
151,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
152,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
153,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
154,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
155,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
156,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
157,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
158,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
159,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
160,"async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
161,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
162,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,True
163,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
164,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",True,True
165,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
166,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",True,True
167,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,True
168,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
169,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
170,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
171,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
172,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
173,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
174,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",True,True
175,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
176,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
177,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",True,True
178,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
179,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
180,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",True,True
181,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
182,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
183,"async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",True,True
184,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
185,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,True
186,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
187,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",True,True
188,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
189,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,True
190,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,True
191,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,True
192,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
193,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,True
194,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
195,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",True,True
196,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
197,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,True
198,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
199,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
200,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,True
201,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
202,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
203,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",True,True
204,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
205,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
206,"async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,True
207,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,True
208,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",True,True
209,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",True,True
210,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",True,True
211,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,True
212,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",True,True
213,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",True,True
214,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,True
215,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,True
216,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,True
217,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,True
218,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",True,True
219,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
220,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,True
221,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,True
222,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",True,True
223,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",True,True
224,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
225,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,True
226,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",True,True
227,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",True,True
228,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
229,"async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",True,True
230,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
231,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,True
232,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
233,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,True
234,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
235,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",True,True
236,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",True,True
237,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
238,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
239,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
240,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
241,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
242,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
243,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,True
244,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
245,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
246,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,True
247,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
248,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
249,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",True,True
250,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
251,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
252,"async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",True,True
253,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,True
254,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,True
255,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,True
256,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",True,True
257,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,True
258,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",True,True
259,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",True,True
260,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,True
261,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,True
262,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",True,True
263,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,True
264,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",True,True
265,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
266,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,True
267,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,True
268,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,True
269,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",True,True
270,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
271,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,True
272,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",True,True
273,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",True,True
274,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
275,"async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",True,True
276,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
277,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",True,True
278,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
279,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",True,True
280,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
281,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",True,True
282,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",True,True
283,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
284,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
285,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
286,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
287,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
288,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
289,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",True,True
290,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
291,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
292,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,True
293,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
294,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
295,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",True,True
296,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
297,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
298,"async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",True,True
299,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
300,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,True
301,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
302,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",True,True
303,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
304,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",True,True
305,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,True
306,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
307,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
308,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
309,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
310,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
311,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
312,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
313,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
314,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
315,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,True
316,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
317,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
318,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",True,True
319,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
320,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
321,"async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,True
322,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
323,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
324,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
325,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
326,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
327,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
328,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
329,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
330,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
331,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
332,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
333,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
334,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
335,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
336,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
337,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
338,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
339,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
340,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
341,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
342,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
343,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
344,"async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
345,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",True,True
346,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",True,True
347,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",True,True
348,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",True,True
349,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",True,True
350,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,True
351,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",True,True
352,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,True
353,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,True
354,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",True,True
355,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,True
356,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,True
357,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,True
358,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
359,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",True,True
360,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,True
361,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",True,True
362,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
363,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",True,True
364,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,True
365,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",True,True
366,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,True
367,"async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",True,True
368,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
369,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,True
370,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
371,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",True,True
372,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
373,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,True
374,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,True
375,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
376,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
377,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
378,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
379,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
380,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
381,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
382,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",True,True
383,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
384,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,True
385,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,True
386,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
387,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,True
388,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
389,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
390,"async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,True
391,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
392,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
393,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
394,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
395,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
396,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
397,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
398,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
399,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
400,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
401,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
402,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
403,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
404,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
405,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
406,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
407,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
408,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
409,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
410,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
411,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
412,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
413,"async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
414,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
415,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
416,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
417,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
418,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
419,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
420,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
421,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
422,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
423,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
424,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
425,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
426,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
427,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
428,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
429,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
430,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
431,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
432,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
433,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
434,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
435,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
436,"async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
437,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
438,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,True
439,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
440,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,True
441,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",True,True
442,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",True,True
443,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",True,True
444,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,True
445,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
446,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
447,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
448,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
449,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
450,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",False,True
451,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",True,True
452,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
453,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,True
454,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,True
455,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",True,True
456,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",True,True
457,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
458,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",True,True
459,"async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,True
460,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
461,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
462,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
463,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
464,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
465,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
466,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
467,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
468,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
469,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
470,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
471,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
472,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
473,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
474,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
475,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
476,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
477,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
478,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
479,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
480,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
481,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
482,"async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
483,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",True,True
484,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
485,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",True,True
486,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
487,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",True,True
488,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
489,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
490,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",True,True
491,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",True,True
492,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",True,True
493,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",True,True
494,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",True,True
495,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,True
496,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
497,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
498,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",True,True
499,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",True,True
500,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
501,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
502,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",True,True
503,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
504,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
505,"async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
506,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
507,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
508,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
509,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
510,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
511,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
512,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
513,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
514,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
515,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
516,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
517,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
518,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
519,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
520,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
521,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
522,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
523,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
524,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
525,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
526,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
527,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
528,"async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
",False,False
529,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_structured_format_followed_1(
    example: dict, prompt: str, response: str
) -> bool:
    required_headers = [
        ""Subject Line"",
        ""Body"",
        ""Pain"",
        ""Agitate"",
        ""Solution"",
        ""Sub-Closing"",
        ""Closing"",
        ""Salutation Format"",
    ]
    return all(header in response for header in required_headers)
",False,False
530,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed_2(example: dict, prompt: str, response: str) -> bool:
    question = ""Does the response include an introduction of a problem, elaboration on the problem, a presented solution, encouragement for the user, and a salutation?""
    return await ask_llm(prompt, response, question)
",False,False
531,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_placeholder_elements_included_3(
    example: dict, prompt: str, response: str
) -> bool:
    return (f""{example['topic']}"" in response) and (f""{example['context']}"" in response)
",False,False
532,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_proper_ending_with_cta_4(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response end with a call to action, a sub-closing, a closing, and a formal salutation?""
    return await ask_llm(prompt, response, question)
",False,False
533,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_word_count_within_limit_5(
    example: dict, prompt: str, response: str
) -> bool:
    max_word_count = example[""word_count""]
    word_count_response = len(response.split())
    return word_count_response <= max_word_count
",False,False
534,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_curiosity_and_action_driven_6(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response foster curiosity and drive action?""
    return await ask_llm(prompt, response, question)
",False,False
535,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_user_onboarding_practices_included_7(
    example: dict, prompt: str, response: str
) -> bool:
    question = ""Does the response utilize user onboarding best practices to encourage users to return to the platform and discover the value in the service?""
    return await ask_llm(prompt, response, question)
",False,False
536,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_encouragement_to_contact_company_8(
    example: dict, prompt: str, response: str
) -> bool:
    contact_phrases = [
        ""reach out"",
        ""don't hesitate to contact"",
        ""looking forward to hearing from you"",
        ""if you have any questions"",
        ""need help getting started"",
    ]
    return any(phrase in response for phrase in contact_phrases)
",False,False
537,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_has_specific_headers_9(example: dict, prompt: str, response: str):
    headers = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Closing:"",
        ""Call to Action:"",
    ]
    return all(header in response for header in headers)
",False,False
538,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_placeholders_10(example: dict, prompt: str, response: str):
    return ""[topic]"" in response and ""[context]"" in response
",False,False
539,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_follows_ordered_steps_11(
    example: dict, prompt: str, response: str
):
    workflow_steps = [""Pain"", ""Agitate"", ""Solution"", ""Sub-Closing"", ""Closing""]
    workflow_indices = [response.find(step) for step in workflow_steps]
    return all(
        workflow_indices[i] < workflow_indices[i + 1]
        for i in range(len(workflow_indices) - 1)
    )
",False,False
540,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_minimum_core_components_present_12(
    example: dict, prompt: str, response: str
):
    sections = [
        ""Pain:"",
        ""Agitate:"",
        ""Solution:"",
        ""Sub-Closing:"",
        ""Aim"",
        ""Closing:"",
        ""Salutation Format"",
    ]
    return len([section for section in sections if section in response]) >= 7
",False,False
541,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_call_to_action_13(example: dict, prompt: str, response: str):
    return ""Call to Action:"" in response
",False,False
542,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_forbidden_words_14(example: dict, prompt: str, response: str):
    forbidden_words = [""Feature"", ""Religion""]
    return not any(word in response for word in forbidden_words)
",True,True
543,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_response_has_adequate_length_and_tone_15(
    example: dict, prompt: str, response: str
):
    question = ""Is the response of adequate length to discuss each section and does it maintain a professional tone?""
    return await ask_llm(prompt, response, question)
",False,False
544,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_consistent_correct_placeholder_usage_16(
    example: dict, prompt: str, response: str
):
    placeholders_used_correctly = ""[topic]"" in response and ""[context]"" in response
    if placeholders_used_correctly:
        topic_placeholder_index = response.find(""[topic]"")
        context_placeholder_index = response.find(""[context]"")
        return topic_placeholder_index < context_placeholder_index
    return False
",False,False
545,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_has_email_structure_17(example: dict, prompt: str, response: str):
    is_subject_present = ""Subject Line:"" in response
    is_body_present = ""Body:"" in response
    return is_subject_present and is_body_present
",False,False
546,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_demonstrates_common_problem_18(
    example: dict, prompt: str, response: str
):
    question = ""Does the response demonstrate a common, real-world problem or challenge related to the topic?""
    return await ask_llm(prompt, response, question)
",False,False
547,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_follows_pain_agitate_solution_19(
    example: dict, prompt: str, response: str
):
    question = ""Does this email follow the Pain-Agitate-Solution strategy effectively?""
    return await ask_llm(prompt, response, question)
",False,False
548,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_length_20(example: dict, prompt: str, response: str):
    word_count = example[""word_count""]
    response_word_count = len(response.split())
    return response_word_count <= int(word_count)
",False,False
549,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_includes_required_components_21(
    example: dict, prompt: str, response: str
):
    question = ""Does the email include pain, agitate, and solution components and relate them to the context?""
    return await ask_llm(prompt, response, question)
",False,False
550,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_excludes_new_user_onboarding_22(
    example: dict, prompt: str, response: str
):
    questioning_new_user = ""Is the email targeting new users to onboard them, or does it focus on existing users?""
    return not await ask_llm(prompt, response, questioning_new_user)
",False,False
551,"async def assert_consistent_professional_tone_24(
    example: dict, prompt: str, response: str
):
    question = ""Does the tone of the email maintain the consistent role of a 'professional marketing copywriter'?""
    return await ask_llm(prompt, response, question)
","async def assert_compelling_subject_line_23(example: dict, prompt: str, response: str):
    question = ""Is the subject line of the email compelling and aligned with the email content?""
    return await ask_llm(prompt, response, question)
",False,False
