func A,func B,A -> B,asked_LLM
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,True
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",True,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",True,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",True,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",True,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",True,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",True,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",True,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",True,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",True,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",True,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",True,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",True,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",True,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",True,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",True,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",True,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",False,True
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
"async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",True,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",True,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",False,True
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",False,True
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",False,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",True,True
"async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",True,True
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",True,True
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
","async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def verify_markdown_headers(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response employs markdown notation for headers.
    """"""
    return all(
        header in response
        for header in (
            ""# Executive Summary:"",
            ""# Negotiation Strategy:"",
            ""# Supplier Summary:"",
            ""# Product Summary:"",
            ""# Market Insights:"",
            ""# Risks and Opportunities:"",
            ""# Potential Questions:"",
        )
    )
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def ensure_all_headers_included(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check if the response includes specified headers: Executive Summary,
    Negotiation Strategy, Supplier Summary, Product Summary,
    Market Insights, Risks and Opportunities, and Potential Questions.
    """"""
    required_headers = [
        ""Executive Summary"",
        ""Negotiation Strategy"",
        ""Supplier Summary"",
        ""Product Summary"",
        ""Market Insights"",
        ""Risks and Opportunities"",
        ""Potential Questions"",
    ]
    return all(header in response for header in required_headers)
",True,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def validate_structured_negotiation_process(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Check that the response reflects an outlined structured process
    for creating the negotiation strategy.
    """"""
    section = ""# Negotiation Strategy:""
    start = response.find(section)
    if start == -1:
        return False

    strategy_content = response[start + len(section) :].strip()
    return any(
        keyword in strategy_content
        for keyword in [""Key objectives"", ""Targets"", ""Fallback positions""]
    )
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def check_for_placeholder_inclusion(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Verify if all the provided placeholders are included in the response.
    """"""
    placeholders = [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]
    return all(
        placeholder.replace(""{"", """").replace(""}"", """") in response
        for placeholder in placeholders
    )
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def ensure_no_extra_sections(example: dict, prompt: str, response: str) -> bool:
    """"""
    Check if the response does not contain any headers or sections not listed in the prompt template.
    """"""
    extraneous_sections = [
        ""# Background:"",
        ""# Introduction:"",
        ""# Conclusion:"",
        ""# Summary:"",
        ""# Analysis:"",
        ""# Discussion:"",
        ""# Recommendations:"",
    ]
    return not any(section in response for section in extraneous_sections)
",True,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assess_language_clarity_and_adaptability(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is written in simple, clear language,
    and remains adaptive and flexible to other factors like market volatility and technological advancements.
    """"""
    question = (
        ""Is the response written in simple and clear language that is easy to read, ""
        ""and does it show an adaptive and flexible approach to factors like market volatility and ""
        ""technological advancements?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def evaluate_understanding_of_supplier_relations(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response reflects an understanding of the relationship with suppliers and how purchasing volume affects bargaining power.
    """"""
    question = (
        ""Does the response reflect an understanding of the company's relationship with the suppliers, ""
        ""emphasizing prior outcomes and experiences, and detail how purchasing volume affects bargaining power?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def validate_target_price_focus(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response aims for the target price reduction specified
    and includes the requested header content format for each specified section.
    """"""
    question = (
        ""Does the response aim for the target price reduction specified, and does it ""
        ""include the requested header content format for each specified section?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def examine_strategy_consistency_and_completeness(
    example: dict, prompt: str, response: str
) -> bool:
    """"""
    Ask the LLM if the response is consistent with the inputs provided,
    reflecting completeness and coherence in strategy.
    """"""
    question = ""Is the response consistent with the provided inputs, showing a complete and coherent strategy?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_detailed_strategy(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes a detailed strategy that considers the ideal outcome,
    suppliers, product or service type, and current standing with the suppliers.
    """"""
    required_elements = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(element in response for element in required_elements)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_workflow_followed(example: dict, prompt: str, response: str):
    """"""
    Check if the response follows the specified workflow: researching the supplier,
    scraping information from the internet, thinking critically about additional searches,
    and not exceeding three iterations.
    """"""
    question = ""Does the response follow the specified workflow including research, scraping, critical thinking about additional searches, and does it assure not to exceed three iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_no_excess_iteration(example: dict, prompt: str, response: str):
    """"""
    Check if the response does not repeat the research iteration process more than three times.
    """"""
    iterations = response.count(""iteration"")
    return iterations <= 3
",True,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_inclusion_of_keywords(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes certain keywords such as 'ideal outcome', 'suppliers',
    'product_service_type', and 'current_standing'.
    """"""
    keywords = [
        ""ideal outcome"",
        ""suppliers"",
        ""product_service_type"",
        ""current_standing"",
    ]
    return all(keyword in response for keyword in keywords)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_facts_only_no_fabrication(example: dict, prompt: str, response: str):
    """"""
    Check if the response avoids making things up and only includes gathered facts and data.
    """"""
    question = ""Does the response only state facts and data that have been gathered, with no fabrication?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_reference_data_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes all reference data and links to back up the research.
    """"""
    return ""http"" in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_no_repeated_phrases(example: dict, prompt: str, response: str):
    """"""
    Check if the response doesn't have unnecessary repeated phrases or sentences.
    """"""
    without_repetition = set(response.split())
    return len(without_repetition) == len(response.split())
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_inclusion_of_supplier_information(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response includes updated and recent information about the suppliers such as current news.
    """"""
    question = ""Does the response include updated and recent information about the suppliers such as current news?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_professional_and_comprehensive_overview(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains a professional tone, factual style, and provides a comprehensive
    overview of the suppliers, product, market insights, risks, opportunities, and potential questions.
    """"""
    question = ""Does the response maintain a professional tone, factual style, and provide a comprehensive overview?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_consistency_and_avoid_unnecessary_repetition(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response maintains consistency by avoiding unnecessary repetition.
    """"""
    question = (
        ""Does the response maintain consistency and avoid unnecessary repetition?""
    )
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_new_search_iteration_evaluation(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response indicates whether there are new things to search after the iterations of research and scraping.
    """"""
    question = ""Does the response reflect an evaluation of whether new searches are needed after research and scraping iterations?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_supplier_summary_inclusion(example: dict, prompt: str, response: str):
    """"""
    Check if the response includes company profile and historical performance in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return (
        ""company profile"" in response[supplier_summary_index:]
        and ""historical performance"" in response[supplier_summary_index:]
    )
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_exclusion_of_past_negotiations_in_supplier_summary(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response does not include past negotiations in the Supplier Summary section.
    """"""
    supplier_summary_index = response.find(""Supplier Summary:"")
    return ""past negotiations"" not in response[supplier_summary_index:]
",True,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is tailored specifically to the situation of each supplier and is not generic.
    """"""
    question = ""Is the response tailored specifically to each situation for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_complete_strategy_addressing_requirements(
    example: dict, prompt: str, response: str
):
    """"""
    Check if the response is complete by providing a strategy that explicitly addresses the requirements and follows the outlined steps.
    """"""
    question = ""Is the response complete, providing a strategy that explicitly addresses the requirements and follows the outlined steps?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_iterates_research_once(example: dict, prompt: str, response: str):
    """"""
    Checks that the response includes a research iteration process and does it only once.
    """"""
    return ""1 iteration"" in response and not ""2 iterations"" in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_in_bullet_format(example: dict, prompt: str, response: str):
    """"""
    Check that the negotiation strategy section of the response is in bullet format.
    """"""
    return ""- "" in response and ""\n-\n"" not in response
",False,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_no_example_in_prompt_template(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that the prompt template does not provide an example of a good response.
    """"""
    return ""No specific example provided in the prompt template."" not in prompt
",False,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_one_scraping_iteration(example: dict, prompt: str, response: str):
    """"""
    Verify that the workflow for research and scraping in the response does not exceed more than one iteration.
    """"""
    question = ""Does the research and scraping process described in the response go through more than one iteration?""
    is_more_than_one_iteration = await ask_llm(prompt, response, question)
    return not is_more_than_one_iteration
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_comprehensive_search_and_facts(
    example: dict, prompt: str, response: str
):
    """"""
    Verify each section (Supplier Summary, Product Summary, Market Insights, etc.) includes comprehensive search and facts.
    """"""
    question = ""Does each section of the response include a comprehensive search and presentation of facts?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_no_made_up_information(example: dict, prompt: str, response: str):
    """"""
    Check the LLM response for any made-up information.
    """"""
    question = (
        ""Does the response contain any made-up information or unsupported claims?""
    )
    is_any_made_up_information = await ask_llm(prompt, response, question)
    return not is_any_made_up_information
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_provided_references_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that references and links are provided to back up research in the response.
    """"""
    question = ""Are there references and links provided in the response to back up the research?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_strategy_tailored_to_each_supplier(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the strategy is tailored specifically for each supplier and is not generic.
    """"""
    question = ""Is the strategy presented in the response tailored specifically for each supplier and not generic?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_correct_placeholders_replacement(
    example: dict, prompt: str, response: str
):
    """"""
    Verify that placeholders in the template are replaced with appropriate example values in the LLM response.
    """"""
    for placeholder in [
        ""{ideal_outcome}"",
        ""{suppliers}"",
        ""{product_service_type}"",
        ""{current_standing}"",
        ""{purchasing_volume_dollars}"",
        ""{target_price_reduction}"",
        ""{other_factors}"",
    ]:
        if placeholder in response:
            return False
    return True
",True,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_ideal_outcome_as_guiding_principle(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the ideal outcome is mentioned as the guiding principle for the strategy in the LLM response.
    """"""
    ideal_outcome = example[""ideal_outcome""]
    return ideal_outcome in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_relationship_with_suppliers_impact(
    example: dict, prompt: str, response: str
):
    """"""
    Check that the relationship with suppliers and its impact on the strategy is accurately represented in the response.
    """"""
    question = ""Does the response correctly assess the relationship with suppliers and its impact on the negotiation strategy?""
    return await ask_llm(prompt, response, question)
",False,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_incorporate_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Confirm that the purchasing volume in dollars is accurately incorporated as a factor in the negotiation strategy.
    """"""
    purchasing_volume = example[""purchasing_volume_dollars""]
    return purchasing_volume in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_achieve_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Ensure the response acknowledges and works towards achieving the target price reduction.
    """"""
    target_price_reduction = example[""target_price_reduction""]
    return target_price_reduction in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_no_repetitions_in_response(example: dict, prompt: str, response: str):
    """"""
    Verify that the LLM response does not contain any repetitions of phrases.
    """"""
    return (
        response.count(
            ""You should include all reference data & links to back up your research;""
        )
        == 1
    )
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_consistency_with_negotiation_strategy(
    example: dict, prompt: str, response: str
):
    """"""
    Check that each section of the response maintains consistency with the negotiation strategy elements.
    """"""
    question = (
        ""Does each section of the response maintain consistency with the negotiation strategy elements""
        "" presented in the prompt?""
    )
    return await ask_llm(prompt, response, question)
",True,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_backs_up_research_with_data_and_links(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response backs up research with data and links.
    """"""
    # This criterion is subjective and may need contextually relevant data to confirm.
    # It is more straight-forward to use expert LLM judgment in this case.
    question = ""Does the response back up the research with actual data and links from credible sources as required?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_does_not_iterate_scraping_more_than_once(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not iterate the scraping and search process more than once.
    """"""
    # Closely look for any mention of a repeated search or scraping iteration.
    iteration_terms = [
        ""second iteration"",
        ""third iteration"",
        ""another iteration"",
        ""repeated search"",
        ""search again"",
        ""scrape again"",
        ""additional search"",
    ]
    for term in iteration_terms:
        if term in response:
            return False
    return True
",True,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_provides_facts_and_data_only(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response provides only facts and data gathered without any made-up information.
    """"""
    # This is subjective and best suited for an expert LLM to evaluate.
    question = ""Does the response only contain facts and data that were gathered, and does not include any made-up information?""
    return await ask_llm(prompt, response, question)
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_includes_product_research(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes research on the mentioned product or service type.
    """"""
    # Looking for specific mentions of product-related research in the response.
    product_service_type = example.get(""product_service_type"", """")
    return product_service_type in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_considers_current_standing_with_suppliers(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response considers the current standing with the suppliers.
    """"""
    # Looking for mentions matching the given current standing with suppliers in the response.
    current_standing = example.get(""current_standing"", """")
    return current_standing in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_includes_purchasing_volume(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the purchasing volume in dollars.
    """"""
    # Looking for the mention of the specific purchasing volume in dollars in the response.
    purchasing_volume_dollars = example.get(""purchasing_volume_dollars"", """")
    return purchasing_volume_dollars in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_addresses_target_price_reduction(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes the target price reduction goal.
    """"""
    # Looking for the specific target price reduction goal in the response.
    target_price_reduction = example.get(""target_price_reduction"", """")
    return target_price_reduction in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_avoids_removed_research_instructions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response does not include specific instructions on doing research that have been removed from the prompt template.
    """"""
    removed_instructions = (
        ""do enough research to gather as much information as possible about the market""
    )
    return removed_instructions not in response
",False,True
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_includes_market_insights(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response analyzes current market conditions.
    """"""
    header = ""Market Insights""
    return header in response and ""current market conditions"" in response
",False,False
"async def assert_response_lists_potential_questions(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response includes potential questions that may arise during the negotiation process.
    """"""
    return ""Potential Questions"" in response and any(
        question in response
        for question in [""Can you"", ""Will you"", ""How will"", ""What if""]
    )
","async def assert_response_identifies_risks_opportunities(
    example: dict, prompt: str, response: str
):
    """"""
    Checks that the response identifies and analyzes potential risks and opportunities associated with the negotiation.
    """"""
    return ""Risks and Opportunities"" in response
",False,True
